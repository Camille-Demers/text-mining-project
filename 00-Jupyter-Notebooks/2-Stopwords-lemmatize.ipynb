{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lemmatisation stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer l'antidictionnaire pour filtrer les données\n",
    "from pandas import *\n",
    "\n",
    "# Stopwords fréquents en français\n",
    "base_path = \"../04-filtrage/\"\n",
    "file_path = base_path + \"stopwords.csv\"\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    stopwords = read_csv(f)\n",
    "    stopwords = [t.lower() for t in stopwords['Stopwords'].tolist()]\n",
    "\n",
    "\n",
    "# Stopwords fréquents en anglais\n",
    "path = '../04-filtrage/stop_words_english.txt'\n",
    "with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "    sw = [w.strip('\\n').lower() for w in f.readlines()]\n",
    "\n",
    "stopwords += sw\n",
    "\n",
    "# Signes de ponctuation\n",
    "import string \n",
    "punct = [s for s in string.punctuation] \n",
    "punct += ['»' ,'©', '']\n",
    "\n",
    "stopwords += punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treetaggerwrapper\n",
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')\n",
    "\n",
    "file_path = '../04-filtrage/mapping_treeTagger_lefff.csv'\n",
    "\n",
    "with open(file_path) as f:\n",
    "    csv = read_csv(f)\n",
    "\n",
    "treeTag = [term for term in csv['TreeTagger'].tolist()] \n",
    "lefff = [term for term in csv['Lefff'].tolist()]\n",
    "\n",
    "mapping = {term : lefff[treeTag.index(term)] for term in treeTag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = [[[t.split('\\t')[0], mapping[t.split('\\t')[1]]] for t in tagger.tag_text(term) if len(t.split('\\t')) >1] for term in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "lemmatizer = FrenchLefffLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "\n",
    "for term in tagged:\n",
    "    for t in term:\n",
    "        term_l = []\n",
    "        if(lemmatizer.lemmatize(t[0], t[1]) == []):\n",
    "            term_l.append(lemmatizer.lemmatize(t[0]))\n",
    "        else:\n",
    "            term_l.append(lemmatizer.lemmatize(t[0], t[1])[0][0]) # [0][0] pour avoir le lemme seul et non (lemme, pos)\n",
    "\n",
    "    lemmas += term_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = set(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../04-filtrage/\"\n",
    "file_path = base_path + \"stopwords_lemmatized.txt\"\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    for term in lemmas:\n",
    "        f.write(term + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a33210152f7d2bd255fb16656f372b633dbf298ed202bbbac20290b0375cadb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
