{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithme</th>\n",
       "      <th>embedding</th>\n",
       "      <th>N features</th>\n",
       "      <th>K (nb clusters)</th>\n",
       "      <th>Score Silhouette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>150</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>5000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>150</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>K-Means</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>5000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>150</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>One-Hot</td>\n",
       "      <td>100%</td>\n",
       "      <td>5000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>150</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Expectation-Maximization</td>\n",
       "      <td>Sentence transformers</td>\n",
       "      <td>100%</td>\n",
       "      <td>5000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  algorithme              embedding N features  \\\n",
       "0                    K-Means                One-Hot       100%   \n",
       "1                    K-Means                One-Hot       100%   \n",
       "2                    K-Means                One-Hot       100%   \n",
       "3                    K-Means                One-Hot       100%   \n",
       "4                    K-Means                One-Hot       100%   \n",
       "5                    K-Means                One-Hot       100%   \n",
       "6                    K-Means                One-Hot       100%   \n",
       "7                    K-Means  Sentence transformers       100%   \n",
       "8                    K-Means  Sentence transformers       100%   \n",
       "9                    K-Means  Sentence transformers       100%   \n",
       "10                   K-Means  Sentence transformers       100%   \n",
       "11                   K-Means  Sentence transformers       100%   \n",
       "12                   K-Means  Sentence transformers       100%   \n",
       "13                   K-Means  Sentence transformers       100%   \n",
       "14  Expectation-Maximization                One-Hot       100%   \n",
       "15  Expectation-Maximization                One-Hot       100%   \n",
       "16  Expectation-Maximization                One-Hot       100%   \n",
       "17  Expectation-Maximization                One-Hot       100%   \n",
       "18  Expectation-Maximization                One-Hot       100%   \n",
       "19  Expectation-Maximization                One-Hot       100%   \n",
       "20  Expectation-Maximization                One-Hot       100%   \n",
       "21  Expectation-Maximization  Sentence transformers       100%   \n",
       "22  Expectation-Maximization  Sentence transformers       100%   \n",
       "23  Expectation-Maximization  Sentence transformers       100%   \n",
       "24  Expectation-Maximization  Sentence transformers       100%   \n",
       "25  Expectation-Maximization  Sentence transformers       100%   \n",
       "26  Expectation-Maximization  Sentence transformers       100%   \n",
       "27  Expectation-Maximization  Sentence transformers       100%   \n",
       "\n",
       "    K (nb clusters) Score Silhouette  \n",
       "0                50             None  \n",
       "1               100             None  \n",
       "2               150             None  \n",
       "3               200             None  \n",
       "4               500             None  \n",
       "5              1000             None  \n",
       "6              5000             None  \n",
       "7                50             None  \n",
       "8               100             None  \n",
       "9               150             None  \n",
       "10              200             None  \n",
       "11              500             None  \n",
       "12             1000             None  \n",
       "13             5000             None  \n",
       "14               50             None  \n",
       "15              100             None  \n",
       "16              150             None  \n",
       "17              200             None  \n",
       "18              500             None  \n",
       "19             1000             None  \n",
       "20             5000             None  \n",
       "21               50             None  \n",
       "22              100             None  \n",
       "23              150             None  \n",
       "24              200             None  \n",
       "25              500             None  \n",
       "26             1000             None  \n",
       "27             5000             None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# algorithmes = ['K-Means', 'Expectation-Maximization']\n",
    "# embeddings = ['One-Hot', 'Sentence transformers']\n",
    "# features = ['100%'] # (100% = aucune réduction de dimensionnalité)\n",
    "# clusters = [50, 100, 150, 200, 500, 1000, 5000]\n",
    "\n",
    "# results = []\n",
    "# for algorithme in algorithmes:\n",
    "#     for embedding in embeddings:\n",
    "#         for feature in features:\n",
    "#             for cluster in clusters:\n",
    "#                 results.append(\\\n",
    "#                 {'algorithme' : algorithme,\\\n",
    "#                     'embedding': embedding, \\\n",
    "#                     'N features': feature, \\\n",
    "#                     'K (nb clusters)' : cluster,\\\n",
    "#                     'Score Silhouette': None})\n",
    "\n",
    "\n",
    "# # On va remplir ce dictionnaire avec les bons scores au fur et à mesure qu'on expérimente\n",
    "# results = DataFrame(results)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpora</th>\n",
       "      <th>Terme</th>\n",
       "      <th>Structure syntaxique</th>\n",
       "      <th>Forme lemmatisée</th>\n",
       "      <th>isMeSHTerm</th>\n",
       "      <th>MeSHID</th>\n",
       "      <th>MesH_prefLabel_fr</th>\n",
       "      <th>MesH_prefLabel_en</th>\n",
       "      <th>isTaxoTerm</th>\n",
       "      <th>Log Likelihood</th>\n",
       "      <th>TF</th>\n",
       "      <th>DF</th>\n",
       "      <th>TF*IDF</th>\n",
       "      <th>OKapiBM25</th>\n",
       "      <th>TF + DF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['chum', 'chuqc', 'chusj', 'cisss_ca', 'cisss_...</td>\n",
       "      <td>services sociaux</td>\n",
       "      <td>NOM ADJ</td>\n",
       "      <td>service social</td>\n",
       "      <td>True</td>\n",
       "      <td>D012947</td>\n",
       "      <td>Services sociaux et travail social (activité)</td>\n",
       "      <td>Social Work</td>\n",
       "      <td>True</td>\n",
       "      <td>1674.908057</td>\n",
       "      <td>40189</td>\n",
       "      <td>15418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.361483</td>\n",
       "      <td>55607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['chum', 'chuqc', 'cisss_ca', 'cisss_cotenord'...</td>\n",
       "      <td>santé publique</td>\n",
       "      <td>NOM ADJ</td>\n",
       "      <td>santé public</td>\n",
       "      <td>True</td>\n",
       "      <td>D011634</td>\n",
       "      <td>Santé publique</td>\n",
       "      <td>Public Health</td>\n",
       "      <td>True</td>\n",
       "      <td>1572.987576</td>\n",
       "      <td>32510</td>\n",
       "      <td>11194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.947189</td>\n",
       "      <td>43704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['chum', 'chuqc', 'chusj', 'cisss_ca', 'cisss_...</td>\n",
       "      <td>santé mentale</td>\n",
       "      <td>NOM ADJ</td>\n",
       "      <td>santé mental</td>\n",
       "      <td>True</td>\n",
       "      <td>D008603</td>\n",
       "      <td>Santé mentale</td>\n",
       "      <td>Mental Health</td>\n",
       "      <td>True</td>\n",
       "      <td>1579.080827</td>\n",
       "      <td>13229</td>\n",
       "      <td>4795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.142062</td>\n",
       "      <td>18024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['chuqc', 'chusj', 'cisss_ca', 'cisss_cotenord...</td>\n",
       "      <td>ministère de la santé</td>\n",
       "      <td>NOM PRP DET:ART NOM</td>\n",
       "      <td>ministère de le santé</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1411.378559</td>\n",
       "      <td>10741</td>\n",
       "      <td>7142</td>\n",
       "      <td>0.553007</td>\n",
       "      <td>21.734060</td>\n",
       "      <td>17883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['chuqc', 'chusj', 'cisss_ca', 'cisss_cotenord...</td>\n",
       "      <td>ministère de la santé et des services</td>\n",
       "      <td>NOM PRP DET:ART NOM KON PRP:det NOM</td>\n",
       "      <td>ministère de le santé et des service</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1107.888160</td>\n",
       "      <td>10560</td>\n",
       "      <td>7061</td>\n",
       "      <td>0.553007</td>\n",
       "      <td>31.111185</td>\n",
       "      <td>17621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>['santeestrie']</td>\n",
       "      <td>centre de crise</td>\n",
       "      <td>NOM PRP NOM</td>\n",
       "      <td>centre de crise</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>84.828851</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.136894</td>\n",
       "      <td>8.582629</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>['laval_sante']</td>\n",
       "      <td>commotion cérébrale</td>\n",
       "      <td>NOM ADJ</td>\n",
       "      <td>commotion cérébral</td>\n",
       "      <td>True</td>\n",
       "      <td>D001924</td>\n",
       "      <td>Commotion de l'encéphale</td>\n",
       "      <td>Brain Concussion</td>\n",
       "      <td>True</td>\n",
       "      <td>388.209903</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.557684</td>\n",
       "      <td>13.725435</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10357</th>\n",
       "      <td>['inesss']</td>\n",
       "      <td>carcinome rénal</td>\n",
       "      <td>NOM ADJ</td>\n",
       "      <td>carcinome rénal</td>\n",
       "      <td>True</td>\n",
       "      <td>D002292</td>\n",
       "      <td>Néphrocarcinome</td>\n",
       "      <td>Carcinoma, Renal Cell</td>\n",
       "      <td>False</td>\n",
       "      <td>61.813956</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.141561</td>\n",
       "      <td>18.359316</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10358</th>\n",
       "      <td>['inesss']</td>\n",
       "      <td>durée de vie</td>\n",
       "      <td>NOM PRP NOM</td>\n",
       "      <td>durée de vie</td>\n",
       "      <td>True</td>\n",
       "      <td>D008136</td>\n",
       "      <td>Longévité</td>\n",
       "      <td>Longevity</td>\n",
       "      <td>False</td>\n",
       "      <td>434.083437</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.184051</td>\n",
       "      <td>21.441105</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10359</th>\n",
       "      <td>['iucpq']</td>\n",
       "      <td>tomographie par émission de positrons</td>\n",
       "      <td>NOM PRP NOM PRP NOM</td>\n",
       "      <td>tomographie par émission de positron</td>\n",
       "      <td>True</td>\n",
       "      <td>D049268</td>\n",
       "      <td>Tomographie par émission de positons</td>\n",
       "      <td>Positron-Emission Tomography</td>\n",
       "      <td>False</td>\n",
       "      <td>389.442395</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317463</td>\n",
       "      <td>21.257671</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10360 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Corpora  \\\n",
       "0      ['chum', 'chuqc', 'chusj', 'cisss_ca', 'cisss_...   \n",
       "1      ['chum', 'chuqc', 'cisss_ca', 'cisss_cotenord'...   \n",
       "2      ['chum', 'chuqc', 'chusj', 'cisss_ca', 'cisss_...   \n",
       "3      ['chuqc', 'chusj', 'cisss_ca', 'cisss_cotenord...   \n",
       "4      ['chuqc', 'chusj', 'cisss_ca', 'cisss_cotenord...   \n",
       "...                                                  ...   \n",
       "10355                                    ['santeestrie']   \n",
       "10356                                    ['laval_sante']   \n",
       "10357                                         ['inesss']   \n",
       "10358                                         ['inesss']   \n",
       "10359                                          ['iucpq']   \n",
       "\n",
       "                                       Terme  \\\n",
       "0                           services sociaux   \n",
       "1                             santé publique   \n",
       "2                              santé mentale   \n",
       "3                      ministère de la santé   \n",
       "4      ministère de la santé et des services   \n",
       "...                                      ...   \n",
       "10355                        centre de crise   \n",
       "10356                    commotion cérébrale   \n",
       "10357                        carcinome rénal   \n",
       "10358                           durée de vie   \n",
       "10359  tomographie par émission de positrons   \n",
       "\n",
       "                      Structure syntaxique  \\\n",
       "0                                  NOM ADJ   \n",
       "1                                  NOM ADJ   \n",
       "2                                  NOM ADJ   \n",
       "3                      NOM PRP DET:ART NOM   \n",
       "4      NOM PRP DET:ART NOM KON PRP:det NOM   \n",
       "...                                    ...   \n",
       "10355                          NOM PRP NOM   \n",
       "10356                              NOM ADJ   \n",
       "10357                              NOM ADJ   \n",
       "10358                          NOM PRP NOM   \n",
       "10359                  NOM PRP NOM PRP NOM   \n",
       "\n",
       "                           Forme lemmatisée  isMeSHTerm   MeSHID  \\\n",
       "0                            service social        True  D012947   \n",
       "1                              santé public        True  D011634   \n",
       "2                              santé mental        True  D008603   \n",
       "3                     ministère de le santé       False      NaN   \n",
       "4      ministère de le santé et des service       False      NaN   \n",
       "...                                     ...         ...      ...   \n",
       "10355                       centre de crise       False      NaN   \n",
       "10356                    commotion cérébral        True  D001924   \n",
       "10357                       carcinome rénal        True  D002292   \n",
       "10358                          durée de vie        True  D008136   \n",
       "10359  tomographie par émission de positron        True  D049268   \n",
       "\n",
       "                                   MesH_prefLabel_fr  \\\n",
       "0      Services sociaux et travail social (activité)   \n",
       "1                                     Santé publique   \n",
       "2                                      Santé mentale   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "...                                              ...   \n",
       "10355                                            NaN   \n",
       "10356                       Commotion de l'encéphale   \n",
       "10357                                Néphrocarcinome   \n",
       "10358                                      Longévité   \n",
       "10359           Tomographie par émission de positons   \n",
       "\n",
       "                  MesH_prefLabel_en  isTaxoTerm  Log Likelihood     TF     DF  \\\n",
       "0                       Social Work        True     1674.908057  40189  15418   \n",
       "1                     Public Health        True     1572.987576  32510  11194   \n",
       "2                     Mental Health        True     1579.080827  13229   4795   \n",
       "3                               NaN       False     1411.378559  10741   7142   \n",
       "4                               NaN       False     1107.888160  10560   7061   \n",
       "...                             ...         ...             ...    ...    ...   \n",
       "10355                           NaN        True       84.828851      3      3   \n",
       "10356              Brain Concussion        True      388.209903      3      3   \n",
       "10357         Carcinoma, Renal Cell       False       61.813956      3      3   \n",
       "10358                     Longevity       False      434.083437      3      3   \n",
       "10359  Positron-Emission Tomography       False      389.442395      2      1   \n",
       "\n",
       "         TF*IDF  OKapiBM25  TF + DF  \n",
       "0      1.000000  26.361483    55607  \n",
       "1      1.000000  18.947189    43704  \n",
       "2      1.000000  24.142062    18024  \n",
       "3      0.553007  21.734060    17883  \n",
       "4      0.553007  31.111185    17621  \n",
       "...         ...        ...      ...  \n",
       "10355  0.136894   8.582629        6  \n",
       "10356  0.557684  13.725435        6  \n",
       "10357  0.141561  18.359316        6  \n",
       "10358  0.184051  21.441105        6  \n",
       "10359  0.317463  21.257671        3  \n",
       "\n",
       "[10360 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../06-clustering/candidate_terms.csv'\n",
    "with open(file_path, encoding='utf-8') as f:\n",
    "    df = read_csv(f).drop(columns=[\"Unnamed: 0\"])\n",
    "    df['Terme'] = df['Terme'].astype('str')\n",
    "    df['TF + DF'] = df['TF'] + df['DF']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "regex = \"[\\w+-]+|\\([\\s+\\w+\\d+-]+\\)|\\w+|\\w\"\n",
    "tokenizex = RegexpTokenizer(regex)\n",
    "\n",
    "file_path = \"../04-filtrage/stopwords.txt\"\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    stopwords = [t.lower().strip('\\n') for t in f.readlines()]\n",
    "\n",
    "def to_tokens(kw, min_chars=2):\n",
    "    tokens = tokenizex.tokenize(str(kw)) # split the string into a list of words\n",
    "    tokens = [word for word in tokens if len(word) > min_chars] \n",
    "    tokens = [str(word) for word in tokens if word not in stopwords] \n",
    "    \n",
    "    tokens = set(tokens) # to remove duplicates\n",
    "    tokens = sorted(tokens) # converts our set back to a list and sorts words in alphabetical order\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terme</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>services sociaux</td>\n",
       "      <td>['services', 'sociaux']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>santé publique</td>\n",
       "      <td>['publique', 'santé']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>santé mentale</td>\n",
       "      <td>['mentale', 'santé']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ministère de la santé</td>\n",
       "      <td>['ministère', 'santé']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ministère de la santé et des services</td>\n",
       "      <td>['ministère', 'santé', 'services']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>centre de crise</td>\n",
       "      <td>['centre', 'crise']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10356</th>\n",
       "      <td>commotion cérébrale</td>\n",
       "      <td>['commotion', 'cérébrale']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10357</th>\n",
       "      <td>carcinome rénal</td>\n",
       "      <td>['carcinome', 'rénal']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10358</th>\n",
       "      <td>durée de vie</td>\n",
       "      <td>['durée', 'vie']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10359</th>\n",
       "      <td>tomographie par émission de positrons</td>\n",
       "      <td>['positrons', 'tomographie', 'émission']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10360 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Terme  \\\n",
       "0                           services sociaux   \n",
       "1                             santé publique   \n",
       "2                              santé mentale   \n",
       "3                      ministère de la santé   \n",
       "4      ministère de la santé et des services   \n",
       "...                                      ...   \n",
       "10355                        centre de crise   \n",
       "10356                    commotion cérébrale   \n",
       "10357                        carcinome rénal   \n",
       "10358                           durée de vie   \n",
       "10359  tomographie par émission de positrons   \n",
       "\n",
       "                                         tokens  \n",
       "0                       ['services', 'sociaux']  \n",
       "1                         ['publique', 'santé']  \n",
       "2                          ['mentale', 'santé']  \n",
       "3                        ['ministère', 'santé']  \n",
       "4            ['ministère', 'santé', 'services']  \n",
       "...                                         ...  \n",
       "10355                       ['centre', 'crise']  \n",
       "10356                ['commotion', 'cérébrale']  \n",
       "10357                    ['carcinome', 'rénal']  \n",
       "10358                          ['durée', 'vie']  \n",
       "10359  ['positrons', 'tomographie', 'émission']  \n",
       "\n",
       "[10360 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df[\"Terme\"].apply(lambda x: to_tokens(\n",
    "    x,\n",
    "    min_chars=2,\n",
    ")).astype(str)\n",
    "\n",
    "df[['Terme', 'tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(df[\"tokens\"].explode()))\n",
    "len(vocab)\n",
    "\n",
    "dim = len(vocab)\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vector(keyword,vocab):\n",
    "    \"\"\"\n",
    "    Calculates vector of keyword on given vocabulary.\n",
    "\n",
    "    Returns vector as a list of values.  \n",
    "    \"\"\"\n",
    "    vector = []\n",
    "    for word in vocab:\n",
    "        if word in keyword:\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Kmeans**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 0.0012640075453869773\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "algo = 'K-Means'\n",
    "embed = 'One-Hot'\n",
    "\n",
    "# for ratio in features:\n",
    "#     r = float(ratio.strip('%'))/100\n",
    "#     n = round(r * dim)\n",
    "#     counter = Counter(df[\"tokens\"].explode().to_list())\n",
    "#     vocab = []\n",
    "#     for key,value in counter.most_common(n):\n",
    "#         vocab.append(key)\n",
    "    \n",
    "df[\"vector\"] = df[\"tokens\"].apply(lambda x: to_vector(x,vocab))\n",
    "\n",
    "X = df['vector'].tolist()\n",
    "kmeans = KMeans(n_clusters=k, init='k-means++', algorithm='elkan', random_state=0, n_init=1, max_iter=200).fit(X)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "score  =  silhouette_score(X, labels)\n",
    "results.loc[((results['algorithme'] == algo) & \\\n",
    "            (results['N features'] == ratio) & \\\n",
    "            (results['K (nb clusters)'] == k) & \\\n",
    "            (results['embedding'] == embed)), 'Score Silhouette'] = score\n",
    "\n",
    "# results\n",
    "print(k, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence transformers embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va utiliser un modèle BERT/sentence transformers (fr) pour extraire nos embeddings plutôt que des simples one-hot encoding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model =  SentenceTransformer(\"dangvantuan/sentence-camembert-base\")\n",
    "\n",
    "sentences = df['Terme'].tolist()\n",
    "embeddings_st = model.encode(sentences, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "for ratio in features:\n",
    "    r = float(ratio.strip('%'))/100\n",
    "    n = round(r * dim)\n",
    "    counter = Counter(df[\"tokens\"].explode().to_list())\n",
    "    vocab = []\n",
    "    for key,value in counter.most_common(n):\n",
    "        vocab.append(key)\n",
    "    \n",
    "    df[\"vector\"] = df[\"tokens\"].apply(lambda x: to_vector(x,vocab))\n",
    "\n",
    "    X = embeddings_st\n",
    "\n",
    "    ###### APPLIQUER PCA AVEC UN NB DE DIMENSION CORRESPONDANT À R POUR FAIRE VARIER LA DIMENSION DES VECTEURS #########\n",
    "\n",
    "    for k in clusters:\n",
    "        kmeans = KMeans(n_clusters=k, init='k-means++', algorithm='elkan', random_state=0, n_init=1, max_iter=200).fit(X)\n",
    "\n",
    "        score  =  silhouette_score(X, kmeans.labels_, metric='cosine')\n",
    "        results.loc[(results['algorithme'] == 'K-Means') & \\\n",
    "                    ((results['N features'] == ratio) & \\\n",
    "                    (results['K (nb clusters)'] == k) & \\\n",
    "                    results['embedding' == 'Sentence transformers']), 'Score Silhouette'] = score\n",
    "\n",
    "results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Expectation-Maximization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ratio in features:\n",
    "    r = float(ratio.strip('%'))/100\n",
    "    n = round(r * dim)\n",
    "    counter = Counter(df[\"tokens\"].explode().to_list())\n",
    "    vocab = []\n",
    "    for key,value in counter.most_common(n):\n",
    "        vocab.append(key)\n",
    "    \n",
    "    df[\"vector\"] = df[\"tokens\"].apply(lambda x: to_vector(x,vocab))\n",
    "\n",
    "    X = df['vector'].tolist()\n",
    "    for k in clusters:\n",
    "        gmm = GaussianMixture(n_components=k, init_params='k-means++', covariance_type='diag').fit(X) # diag pour gérer MemoryError\n",
    "        labels = gmm.predict(X)\n",
    "\n",
    "        score  =  silhouette_score(X, labels)\n",
    "        results.loc[((results['algorithme'] == 'Expectation-Maximization') &\n",
    "                    (results['N features'] == ratio) & \\\n",
    "                    (results['K (nb clusters)'] == k) & \\\n",
    "                    (results['embedding'] == 'One-Hot')), 'Score Silhouette'] = score\n",
    "\n",
    "results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence transformers embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "for ratio in features:\n",
    "    r = float(ratio.strip('%'))/100\n",
    "    n = round(r * dim)\n",
    "    counter = Counter(df[\"tokens\"].explode().to_list())\n",
    "    vocab = []\n",
    "    for key,value in counter.most_common(n):\n",
    "        vocab.append(key)\n",
    "    \n",
    "    df[\"vector\"] = df[\"tokens\"].apply(lambda x: to_vector(x,vocab))\n",
    "\n",
    "    X = embeddings_st\n",
    "\n",
    "    ###### APPLIQUER PCA AVEC UN NB DE DIMENSION CORRESPONDANT À R POUR FAIRE VARIER LA DIMENSION DES VECTEURS #########\n",
    "\n",
    "    for k in clusters:\n",
    "        gmm = GaussianMixture(n_components=k, init_params='k-means++', covariance_type='diag').fit(X) # diag pour gérer MemoryError\n",
    "        labels = gmm.predict(X)\n",
    "\n",
    "\n",
    "        score  =  silhouette_score(X, labels, metric='cosine')\n",
    "        results.loc[(results['algorithme'] == 'Expectation-Maximization') & \\\n",
    "                    ((results['N features'] == ratio) & \\\n",
    "                    (results['K (nb clusters)'] == k) & \\\n",
    "                    results['embedding' == 'Sentence transformers']), 'Score Silhouette'] = score\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79bb76bbc4f9ba1f8df5efe8db67aae07079a51dc7b5004f49990e90f5993a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
