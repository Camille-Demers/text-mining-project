{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c662c7d",
   "metadata": {},
   "source": [
    "## **2. Prétraitement**\n",
    "- Segmentation (phrases)\n",
    "- Tokenization (mots)\n",
    "- Étiquetage morphosyntaxique (POS Tagging) \n",
    "- Lemmatisation\n",
    "- Filtrage (stopwords)\n",
    "- Extraction de termes complexes (MWE / n-grammes / segments répétés)\n",
    "- Chunking / Filtrage par patrons syntaxiques (basés sur les patrons fréquents dans les MeSH)\n",
    "- Extraction de collocations significatives (en fonction du Log-likelihood ratio)\n",
    "- Extraction de concordances (KWIC) pour un ensemble de mots-clés d'intérêt\n",
    "- Extraction de termes MeSH et SNOMED présents dans les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32e8cb0",
   "metadata": {},
   "source": [
    "Ajouts (2022-07-12)\n",
    "- LLR (semble fonctionner maintenant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece38e9",
   "metadata": {},
   "source": [
    "### **Lire le corpus** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a62415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, re, pandas, random\n",
    "from os import listdir, chdir, path\n",
    "from pathlib import Path\n",
    "\n",
    "acteur = 'chum'\n",
    "sous_corpus = False \n",
    "tag = ''\n",
    "\n",
    "# Change the directory\n",
    "if sous_corpus:\n",
    "    base_path = '../03-corpus/2-sous-corpus/'\n",
    "    file_path = path.join(base_path, acteur, tag)\n",
    "\n",
    "else: \n",
    "    base_path = '../03-corpus/2-data/1-fr/'\n",
    "    file_path = path.join(base_path, acteur) + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31c5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "with open(file_path, \"r\", encoding = \"UTF-8\") as f:\n",
    "        data = read_csv(file_path)\n",
    "        text = data['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4fda380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a un corpus de 2299 documents.\n"
     ]
    }
   ],
   "source": [
    "nb_docs = len(text)\n",
    "\n",
    "print(\"On a un corpus de {} documents.\".format(nb_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89c4d8",
   "metadata": {},
   "source": [
    "### **Extraire un échantillon aléatoire**\n",
    "\n",
    "Sinon, on n'arrive pas à traiter la totalité du corpus pour des raisons de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69841ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On va travailler sur un échantillon correspondant à environ 40 % des documents du corpus, soit 460 documents\n"
     ]
    }
   ],
   "source": [
    "n = round(0.2 * nb_docs)\n",
    "corpus = random.sample(text, n)\n",
    "\n",
    "print(\"On va travailler sur un échantillon correspondant à environ 40 % des documents du corpus, soit {} documents\". format(len(corpus)))\n",
    "\n",
    "corpus = \" \".join([(re.sub('\\d', '', t.strip('\\n').lower().replace('’', '\\''))) for t in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a4b16",
   "metadata": {},
   "source": [
    "**NLTK**\\\n",
    "https://www.nltk.org/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31145e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download(['popular'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a63c6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = '!#$%&()*+,-/:;<=>?@[\\]^_{|}~©'\n",
    "\n",
    "for t in punct:\n",
    "    corpus = corpus.replace(t, ' ').replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b5d73",
   "metadata": {},
   "source": [
    "### **Filtrage (MWE - stopwords formés de plusieurs tokens)**\n",
    "Surtout pour filtrer les expressions relatives à l'architecture d'information / navigation Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7820d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../04-filtrage/mwe_stopwords.txt'\n",
    "\n",
    "with open (file_path, 'r', encoding='utf-8') as f:\n",
    "    mwe_sw = [t.lower().strip('\\n') for t in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29a19b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mwe in mwe_sw:\n",
    "    corpus = corpus.replace(mwe, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8980c335",
   "metadata": {},
   "source": [
    "### **Tokenisation / POS tagging** (TreeTagger)  \n",
    "https://github.com/miotto/treetagger-python/blob/master/README.rst  \n",
    "https://treetaggerwrapper.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb94eec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec le RegExpTokenizer, notre corpus contient 781802 tokens.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Seulement les caractères alphabétiques\n",
    "tokenizer_re = RegexpTokenizer(r\"\\w\\'|\\w+\")\n",
    "\n",
    "tokens = tokenizer_re.tokenize(corpus)\n",
    "len_corpus = len(tokens)\n",
    "\n",
    "print(\"Avec le RegExpTokenizer, notre corpus contient {} tokens.\".format(len_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1415fad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jamal',\n",
       " 'rahima',\n",
       " 'chum',\n",
       " 'navigation',\n",
       " 'patients',\n",
       " 'répertoire',\n",
       " 'enseignement',\n",
       " 'et',\n",
       " 'académie',\n",
       " 'centre',\n",
       " 'de',\n",
       " 'recherche',\n",
       " 'innovation',\n",
       " 'nouvelles',\n",
       " 'carrières',\n",
       " 'english',\n",
       " 'menu',\n",
       " 'sub',\n",
       " 'haut',\n",
       " 'répertoire',\n",
       " 'centre',\n",
       " 'de',\n",
       " 'recherche',\n",
       " 'du',\n",
       " 'chum',\n",
       " 'chercheurs',\n",
       " 'jamal',\n",
       " 'rahima',\n",
       " 'm',\n",
       " 'd',\n",
       " 'b',\n",
       " 'sc',\n",
       " 'frcpc',\n",
       " 'chercheur',\n",
       " 'investigateur',\n",
       " 'centre',\n",
       " 'de',\n",
       " 'recherche',\n",
       " 'du',\n",
       " 'chum',\n",
       " 'axe',\n",
       " 'de',\n",
       " 'recherche',\n",
       " 'cancer',\n",
       " 'directrice',\n",
       " 'médicale',\n",
       " 'unité',\n",
       " \"d'\",\n",
       " 'innovations',\n",
       " 'thérapeutiques']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c07b565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \" \".join(tokens).replace(\"' \", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047334bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\p1115145\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\treetaggerwrapper.py:739: FutureWarning: Possible nested set at position 8\n",
      "  punct2find_re = re.compile(\"([^ ])([[\" + ALONEMARKS + \"])\",\n",
      "c:\\Users\\p1115145\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\treetaggerwrapper.py:2043: FutureWarning: Possible nested set at position 152\n",
      "  DnsHostMatch_re = re.compile(\"(\" + DnsHost_expression + \")\",\n",
      "c:\\Users\\p1115145\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\treetaggerwrapper.py:2067: FutureWarning: Possible nested set at position 409\n",
      "  UrlMatch_re = re.compile(UrlMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
      "c:\\Users\\p1115145\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\treetaggerwrapper.py:2079: FutureWarning: Possible nested set at position 192\n",
      "  EmailMatch_re = re.compile(EmailMatch_expression, re.VERBOSE | re.IGNORECASE)\n"
     ]
    }
   ],
   "source": [
    "import treetaggerwrapper\n",
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c195d",
   "metadata": {},
   "source": [
    "### **Mapping POS Tags** (FRMG)\n",
    "\n",
    "Pour utiliser adéquatement notre lemmatiseur par la suite (FrenchLefffLemmatizer), on va mapper les étiquettes morphosyntaxiques du TreeTagger à celles que prend le lemmatiseur (celles issues de FRMG)\n",
    "\n",
    "http://alpage.inria.fr/frmgwiki/content/tagset-frmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7682234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../04-filtrage/mapping_treeTagger_lefff.csv'\n",
    "\n",
    "with open(file_path) as f:\n",
    "    csv = read_csv(f)\n",
    "\n",
    "treeTag = [term for term in csv['TreeTagger'].tolist()] \n",
    "lefff = [term for term in csv['Lefff'].tolist()]\n",
    "\n",
    "mapping = {term : lefff[treeTag.index(term)] for term in treeTag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d991e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged = [[t.split('\\t')[0], mapping[t.split('\\t')[1]]] for t in tagger.tag_text(corpus)]\n",
    "tagged = [(t.split('\\t')[0], mapping[t.split('\\t')[1]]) for t in tagger.tag_text(corpus)]\n",
    "\n",
    "\n",
    "#if len(t.split('\\t')) >1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cb36efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jamal', 'adj'),\n",
       " ('rahima', 'nc'),\n",
       " ('chum', 'nc'),\n",
       " ('navigation', 'nc'),\n",
       " ('patients', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('enseignement', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('académie', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('nouvelles', 'adj'),\n",
       " ('carrières', 'nc'),\n",
       " ('english', 'adj'),\n",
       " ('menu', 'adj'),\n",
       " ('sub', 'nc'),\n",
       " ('haut', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('chercheurs', 'adj'),\n",
       " ('jamal', 'adj'),\n",
       " ('rahima', 'v'),\n",
       " ('m', 'nc'),\n",
       " ('d', 'v'),\n",
       " ('b', 'nc'),\n",
       " ('sc', 'adj'),\n",
       " ('frcpc', 'nc'),\n",
       " ('chercheur', 'adj'),\n",
       " ('investigateur', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('axe', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('cancer', 'nc'),\n",
       " ('directrice', 'adj'),\n",
       " ('médicale', 'adj'),\n",
       " ('unité', 'nc'),\n",
       " (\"d'\", 'prep'),\n",
       " ('innovations', 'nc'),\n",
       " ('thérapeutiques', 'adj'),\n",
       " ('crchum', 'nc'),\n",
       " ('professeure', 'v'),\n",
       " ('adjointe', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('clinique', 'adj'),\n",
       " ('département', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('médecine', 'nc'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'nc'),\n",
       " ('coordonnées', 'adj'),\n",
       " ('rahima', 'v'),\n",
       " ('jamal', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('ssss', 'adj'),\n",
       " ('gouv', 'adj'),\n",
       " ('qc', 'nc'),\n",
       " ('ca', 'v'),\n",
       " ('poste', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('patient', 'nc'),\n",
       " ('qui', 'pro'),\n",
       " ('a', 'v'),\n",
       " ('besoin', 'nc'),\n",
       " (\"d'\", 'prep'),\n",
       " ('assistance', 'nc'),\n",
       " ('immédiate', 'adj'),\n",
       " ('ne', 'adv'),\n",
       " ('doit', 'v'),\n",
       " ('pas', 'adv'),\n",
       " ('communiquer', 'v'),\n",
       " ('directement', 'adv'),\n",
       " ('avec', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('chercheur', 'nc'),\n",
       " ('il', 'pro'),\n",
       " ('doit', 'v'),\n",
       " ('plutôt', 'adv'),\n",
       " ('appeler', 'v'),\n",
       " ('le', 'det'),\n",
       " ('cabinet', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('médecin', 'nc'),\n",
       " ('ou', 'csu'),\n",
       " ('prendre', 'v'),\n",
       " (\"d'\", 'prep'),\n",
       " ('autres', 'adj'),\n",
       " ('mesures', 'nc'),\n",
       " ('appropriées', 'v'),\n",
       " ('comme', 'csu'),\n",
       " ('se', 'pro'),\n",
       " ('rendre', 'v'),\n",
       " ('au', 'prep'),\n",
       " ('service', 'nc'),\n",
       " (\"d'\", 'prep'),\n",
       " ('urgence', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('plus', 'adv'),\n",
       " ('proche', 'adj'),\n",
       " ('mots', 'nc'),\n",
       " ('clés', 'nc'),\n",
       " ('hémato', 'adj'),\n",
       " ('oncologie', 'nc'),\n",
       " ('études', 'nc'),\n",
       " ('cliniques', 'adj'),\n",
       " ('précoces', 'adj'),\n",
       " ('recherche', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('intérêts', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('mélanome', 'nc'),\n",
       " ('études', 'nc'),\n",
       " ('cliniques', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('phase', 'nc'),\n",
       " ('i', 'adj'),\n",
       " ('et', 'csu'),\n",
       " ('ii', 'adj'),\n",
       " ('publications', 'nc'),\n",
       " ('publications', 'nc'),\n",
       " ('indexées', 'v'),\n",
       " ('sur', 'prep'),\n",
       " ('pubmed', 'adj'),\n",
       " ('publications', 'nc'),\n",
       " ('indexées', 'v'),\n",
       " ('sur', 'prep'),\n",
       " ('researchgate', 'nc'),\n",
       " ('nouvelles', 'adj'),\n",
       " ('recherche', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('précoce', 'adj'),\n",
       " ('au', 'prep'),\n",
       " ('québec', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('crchum', 'nc'),\n",
       " ('à', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('avant', 'prep'),\n",
       " ('scène', 'nc'),\n",
       " ('recherche', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('précoce', 'adj'),\n",
       " ('notre', 'det'),\n",
       " ('unité', 'nc'),\n",
       " (\"d'\", 'prep'),\n",
       " ('innovations', 'nc'),\n",
       " ('thérapeutiques', 'adj'),\n",
       " ('en', 'prep'),\n",
       " ('orbite', 'nc'),\n",
       " ('nomination', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('rahima', 'nc'),\n",
       " ('jamal', 'adj'),\n",
       " ('comme', 'csu'),\n",
       " ('responsable', 'adj'),\n",
       " ('médicale', 'adj'),\n",
       " ('de', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('unité', 'nc'),\n",
       " (\"d'\", 'prep'),\n",
       " ('innovations', 'nc'),\n",
       " ('thérapeutiques', 'adj'),\n",
       " ('greffe', 'v'),\n",
       " ('fécale', 'adj'),\n",
       " ('et', 'csu'),\n",
       " ('immunothérapie', 'nc'),\n",
       " ('un', 'det'),\n",
       " ('cocktail', 'nc'),\n",
       " ('gagnant', 'v'),\n",
       " ('pour', 'prep'),\n",
       " ('vaincre', 'v'),\n",
       " ('le', 'det'),\n",
       " ('mélanome', 'nc'),\n",
       " ('recherche', 'v'),\n",
       " ('rechercher', 'v'),\n",
       " ('médias', 'nc'),\n",
       " ('sociaux', 'adj'),\n",
       " ('crchum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('est', 'v'),\n",
       " ('affilié', 'v'),\n",
       " ('à', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'adj'),\n",
       " ('portail', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('réseau', 'nc'),\n",
       " ('québécois', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('la', 'det'),\n",
       " ('télésanté', 'adj'),\n",
       " ('offre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('formations', 'nc'),\n",
       " ('laboratoires', 'nc'),\n",
       " ('fondation', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('bénévolat', 'nc'),\n",
       " ('bibliothèque', 'nc'),\n",
       " ('comité', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('usagers', 'adj'),\n",
       " ('commissaire', 'nc'),\n",
       " ('local', 'adj'),\n",
       " ('aux', 'prep'),\n",
       " ('plaintes', 'nc'),\n",
       " ('politique', 'adj'),\n",
       " (\"d'\", 'prep'),\n",
       " ('approvisionnement', 'nc'),\n",
       " ('regroupement', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('retraités', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('ruisss', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('confidentialité', 'nc'),\n",
       " ('avertissement', 'nc'),\n",
       " ('recherche', 'nc'),\n",
       " ('en', 'prep'),\n",
       " ('oncologie', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('précision', 'nc'),\n",
       " ('million', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('pour', 'prep'),\n",
       " ('une', 'det'),\n",
       " ('équipe', 'nc'),\n",
       " ('codirigée', 'v'),\n",
       " ('par', 'prep'),\n",
       " ('la', 'det'),\n",
       " ('dre', 'adj'),\n",
       " ('diane', 'nc'),\n",
       " ('provencher', 'nc'),\n",
       " ('chum', 'nc'),\n",
       " ('navigation', 'nc'),\n",
       " ('patients', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('enseignement', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('académie', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('nouvelles', 'adj'),\n",
       " ('carrières', 'nc'),\n",
       " ('menu', 'adj'),\n",
       " ('sub', 'nc'),\n",
       " ('haut', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('nouvelles', 'adj'),\n",
       " ('recherche', 'nc'),\n",
       " ('en', 'prep'),\n",
       " ('oncologie', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('précision', 'nc'),\n",
       " ('million', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('pour', 'prep'),\n",
       " ('une', 'det'),\n",
       " ('équipe', 'nc'),\n",
       " ('codirigée', 'v'),\n",
       " ('par', 'prep'),\n",
       " ('la', 'det'),\n",
       " ('dre', 'adj'),\n",
       " ('diane', 'nc'),\n",
       " ('provencher', 'nc'),\n",
       " ('juillet', 'nc'),\n",
       " (\"l'\", 'det'),\n",
       " ('équipe', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('menée', 'v'),\n",
       " ('par', 'prep'),\n",
       " ('la', 'det'),\n",
       " ('d', 'nc'),\n",
       " ('re', 'v'),\n",
       " ('diane', 'nc'),\n",
       " ('provencher', 'v'),\n",
       " ('et', 'csu'),\n",
       " ('la', 'det'),\n",
       " ('d', 'nc'),\n",
       " ('re', 'v'),\n",
       " ('helen', 'adj'),\n",
       " ('mackay', 'nc'),\n",
       " ('sunnybrook', 'adj'),\n",
       " ('health', 'nc'),\n",
       " ('sciences', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('vient', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('recevoir', 'v'),\n",
       " ('un', 'det'),\n",
       " ('million', 'nc'),\n",
       " ('afin', 'csu'),\n",
       " (\"d'\", 'prep'),\n",
       " ('évaluer', 'v'),\n",
       " ('une', 'det'),\n",
       " ('nouvelle', 'adj'),\n",
       " ('combinaison', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('traitements', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('cancer', 'nc'),\n",
       " ('de', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('ovaire', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('du', 'prep'),\n",
       " ('cancer', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('sein', 'nc'),\n",
       " ('accordé', 'v'),\n",
       " ('par', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('organisme', 'nc'),\n",
       " ('à', 'prep'),\n",
       " ('but', 'nc'),\n",
       " ('non', 'adv'),\n",
       " ('lucratif', 'adj'),\n",
       " ('exactis', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('ce', 'pro'),\n",
       " ('financement', 'nc'),\n",
       " ('permettra', 'v'),\n",
       " ('la', 'det'),\n",
       " ('tenue', 'nc'),\n",
       " (\"d'\", 'prep'),\n",
       " ('un', 'det'),\n",
       " ('essai', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('multicentrique', 'adj'),\n",
       " ('dans', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('réseau', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('exactis', 'adj'),\n",
       " ('qui', 'pro'),\n",
       " ('regroupe', 'v'),\n",
       " ('onze', '-'),\n",
       " ('grands', 'adj'),\n",
       " ('établissements', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('soins', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('cancer', 'nc'),\n",
       " ('au', 'prep'),\n",
       " ('canada', 'nc'),\n",
       " (\"l'\", 'det'),\n",
       " ('essai', 'nc'),\n",
       " ('découle', 'v'),\n",
       " ('directement', 'adv'),\n",
       " ('de', 'prep'),\n",
       " ('recherches', 'nc'),\n",
       " ('menées', 'v'),\n",
       " ('dans', 'prep'),\n",
       " ('les', 'det'),\n",
       " ('laboratoires', 'nc'),\n",
       " (\"d'\", 'prep'),\n",
       " ('mes', 'det'),\n",
       " ('masson', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('de', 'prep'),\n",
       " ('francis', 'nc'),\n",
       " ('rodier', 'adj'),\n",
       " ('crchum', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('de', 'prep'),\n",
       " ('david', 'adj'),\n",
       " ('andrews', 'nc'),\n",
       " ('university', 'adj'),\n",
       " ('of', 'adj'),\n",
       " ('toronto', 'nc'),\n",
       " ('ces', 'pro'),\n",
       " ('derniers', 'nc'),\n",
       " ('sont', 'v'),\n",
       " ('les', 'det'),\n",
       " ('responsables', 'adj'),\n",
       " ('scientifiques', 'adj'),\n",
       " ('du', 'prep'),\n",
       " ('projet', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('espèrent', 'v'),\n",
       " ('ouvrir', 'v'),\n",
       " ('la', 'det'),\n",
       " ('voie', 'nc'),\n",
       " ('à', 'prep'),\n",
       " ('une', 'det'),\n",
       " ('nouvelle', 'adj'),\n",
       " ('approche', 'nc'),\n",
       " ('pour', 'prep'),\n",
       " ('personnaliser', 'v'),\n",
       " ('le', 'det'),\n",
       " ('traitement', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('femmes', 'nc'),\n",
       " ('atteintes', 'v'),\n",
       " ('des', 'prep'),\n",
       " ('cancers', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('sein', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('de', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('ovaire', 'nc'),\n",
       " ('un', 'det'),\n",
       " ('comité', 'nc'),\n",
       " (\"d'\", 'prep'),\n",
       " ('experts', 'nc'),\n",
       " ('internationaux', 'adj'),\n",
       " ('a', 'v'),\n",
       " ('sélectionné', 'v'),\n",
       " ('le', 'det'),\n",
       " ('projet', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('des', 'prep'),\n",
       " ('d', 'nc'),\n",
       " ('rs', 'v'),\n",
       " ('provencher', 'v'),\n",
       " ('et', 'csu'),\n",
       " ('mackay', 'nc'),\n",
       " ('parmi', 'prep'),\n",
       " ('des', 'prep'),\n",
       " ('demandes', 'nc'),\n",
       " ('provenant', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('tout', 'pro'),\n",
       " ('le', 'det'),\n",
       " ('pays', 'nc'),\n",
       " ('dans', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('domaine', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('la', 'det'),\n",
       " ('médecine', 'nc'),\n",
       " ('personnalisée', 'v'),\n",
       " ('qu', 'v'),\n",
       " ('elles', 'pro'),\n",
       " ('soient', 'v'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('sunnybrook', 'nc'),\n",
       " ('health', 'nc'),\n",
       " ('sciences', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('hôpital', 'nc'),\n",
       " (\"d'\", 'prep'),\n",
       " ('ottawa', 'nc'),\n",
       " ('de', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('hôpital', 'nc'),\n",
       " ('général', 'adj'),\n",
       " ('juif', 'adj'),\n",
       " ('ou', 'csu'),\n",
       " ('du', 'prep'),\n",
       " ('london', 'nc'),\n",
       " ('health', 'nc'),\n",
       " ('sciences', 'nc'),\n",
       " ('centre', 'v'),\n",
       " ('les', 'det'),\n",
       " ('patientes', 'nc'),\n",
       " ('atteintes', 'v'),\n",
       " (\"d'\", 'prep'),\n",
       " ('un', 'det'),\n",
       " ('carcinome', 'nc'),\n",
       " ('séreux', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('haut', 'adj'),\n",
       " ('grade', 'nc'),\n",
       " ('de', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('ovaire', 'nc'),\n",
       " ('et', 'csu'),\n",
       " (\"d'\", 'prep'),\n",
       " ('un', 'det'),\n",
       " ('cancer', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('sein', 'nc'),\n",
       " ('triple', 'adj'),\n",
       " ('négatif', 'adj'),\n",
       " ('et', 'csu'),\n",
       " ('ayant', 'v'),\n",
       " ('peu', 'adv'),\n",
       " (\"d'\", 'prep'),\n",
       " ('options', 'nc'),\n",
       " ('thérapeutiques', 'adj'),\n",
       " ('pourront', 'v'),\n",
       " ('participer', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('cet', 'pro'),\n",
       " ('essai', 'nc'),\n",
       " ('facebook', 'nc'),\n",
       " ('twitter', 'v'),\n",
       " ('linkedin', 'adj'),\n",
       " ('print', 'nc'),\n",
       " ('recherche', 'v'),\n",
       " ('rechercher', 'v'),\n",
       " ('médias', 'nc'),\n",
       " ('sociaux', 'adj'),\n",
       " ('crchum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('est', 'v'),\n",
       " ('affilié', 'v'),\n",
       " ('à', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'adj'),\n",
       " ('portail', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('réseau', 'nc'),\n",
       " ('québécois', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('la', 'det'),\n",
       " ('télésanté', 'adj'),\n",
       " ('offre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('formations', 'nc'),\n",
       " ('laboratoires', 'nc'),\n",
       " ('fondation', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('bénévolat', 'nc'),\n",
       " ('bibliothèque', 'nc'),\n",
       " ('comité', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('usagers', 'adj'),\n",
       " ('commissaire', 'nc'),\n",
       " ('local', 'adj'),\n",
       " ('aux', 'prep'),\n",
       " ('plaintes', 'nc'),\n",
       " ('politique', 'adj'),\n",
       " (\"d'\", 'prep'),\n",
       " ('approvisionnement', 'nc'),\n",
       " ('regroupement', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('retraités', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('ruisss', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('confidentialité', 'nc'),\n",
       " ('avertissement', 'nc'),\n",
       " ('leclerc', 'nc'),\n",
       " ('isabelle', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('navigation', 'nc'),\n",
       " ('patients', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('enseignement', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('académie', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('nouvelles', 'adj'),\n",
       " ('carrières', 'nc'),\n",
       " ('english', 'adj'),\n",
       " ('menu', 'adj'),\n",
       " ('sub', 'nc'),\n",
       " ('haut', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('chercheurs', 'adj'),\n",
       " ('leclerc', 'nc'),\n",
       " ('isabelle', 'adj'),\n",
       " ('chercheur', 'adj'),\n",
       " ('régulier', 'adj'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('axe', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('cardiométabolique', 'adj'),\n",
       " ('professeure', 'nc'),\n",
       " ('titulaire', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('clinique', 'adj'),\n",
       " ('département', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('médecine', 'nc'),\n",
       " ('faculté', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('médecine', 'nc'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'nc'),\n",
       " ('coordonnées', 'v'),\n",
       " ('isabelle', 'adj'),\n",
       " ('leclerc', 'nc'),\n",
       " ('chum', 'nc'),\n",
       " ('ssss', 'adj'),\n",
       " ('gouv', 'adj'),\n",
       " ('qc', 'nc'),\n",
       " ('ca', 'v'),\n",
       " ('poste', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('patient', 'nc'),\n",
       " ('qui', 'pro'),\n",
       " ('a', 'v'),\n",
       " ('besoin', 'nc'),\n",
       " (\"d'\", 'prep'),\n",
       " ('assistance', 'nc'),\n",
       " ('immédiate', 'adj'),\n",
       " ('ne', 'adv'),\n",
       " ('doit', 'v'),\n",
       " ('pas', 'adv'),\n",
       " ('communiquer', 'v'),\n",
       " ('directement', 'adv'),\n",
       " ('avec', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('chercheur', 'nc'),\n",
       " ('il', 'pro'),\n",
       " ('doit', 'v'),\n",
       " ('plutôt', 'adv'),\n",
       " ('appeler', 'v'),\n",
       " ('le', 'det'),\n",
       " ('cabinet', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('médecin', 'nc'),\n",
       " ('ou', 'csu'),\n",
       " ('prendre', 'v'),\n",
       " (\"d'\", 'prep'),\n",
       " ('autres', 'adj'),\n",
       " ('mesures', 'nc'),\n",
       " ('appropriées', 'v'),\n",
       " ('comme', 'csu'),\n",
       " ('se', 'pro'),\n",
       " ('rendre', 'v'),\n",
       " ('au', 'prep'),\n",
       " ('service', 'nc'),\n",
       " (\"d'\", 'prep'),\n",
       " ('urgence', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('plus', 'adv'),\n",
       " ('proche', 'adj'),\n",
       " ('publications', 'nc'),\n",
       " ('pubmed', 'adj'),\n",
       " ('recherche', 'v'),\n",
       " ('rechercher', 'v'),\n",
       " ('médias', 'nc'),\n",
       " ('sociaux', 'adj'),\n",
       " ('crchum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('est', 'v'),\n",
       " ('affilié', 'v'),\n",
       " ('à', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'adj'),\n",
       " ('portail', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('réseau', 'nc'),\n",
       " ('québécois', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('la', 'det'),\n",
       " ('télésanté', 'adj'),\n",
       " ('offre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('formations', 'nc'),\n",
       " ('laboratoires', 'nc'),\n",
       " ('fondation', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('bénévolat', 'nc'),\n",
       " ('bibliothèque', 'nc'),\n",
       " ('comité', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('usagers', 'adj'),\n",
       " ('commissaire', 'nc'),\n",
       " ('local', 'adj'),\n",
       " ('aux', 'prep'),\n",
       " ('plaintes', 'nc'),\n",
       " ('politique', 'adj'),\n",
       " (\"d'\", 'prep'),\n",
       " ('approvisionnement', 'nc'),\n",
       " ('regroupement', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('retraités', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('ruisss', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('confidentialité', 'nc'),\n",
       " ('avertissement', 'nc'),\n",
       " ('traiter', 'v'),\n",
       " ('un', 'det'),\n",
       " ('avc', 'nc'),\n",
       " ('par', 'prep'),\n",
       " ('une', 'det'),\n",
       " ('intervention', 'nc'),\n",
       " ('la', 'det'),\n",
       " ('thrombectomie', 'nc'),\n",
       " ('endovasculaire', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('navigation', 'nc'),\n",
       " ('patients', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('enseignement', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('académie', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('nouvelles', 'adj'),\n",
       " ('carrières', 'nc'),\n",
       " ('english', 'adj'),\n",
       " ('menu', 'adj'),\n",
       " ('sub', 'nc'),\n",
       " ('haut', 'adv'),\n",
       " ('répertoire', 'nc'),\n",
       " ('traiter', 'v'),\n",
       " ('un', 'det'),\n",
       " ('avc', 'nc'),\n",
       " ('par', 'prep'),\n",
       " ('une', 'det'),\n",
       " ('intervention', 'nc'),\n",
       " ('la', 'det'),\n",
       " ('thrombectomie', 'nc'),\n",
       " ('endovasculaire', 'adj'),\n",
       " ('vous', 'pro'),\n",
       " ('allez', 'v'),\n",
       " ('bientôt', 'adv'),\n",
       " ('avoir', 'v'),\n",
       " ('ou', 'csu'),\n",
       " ('vous', 'pro'),\n",
       " ('venez', 'v'),\n",
       " (\"d'\", 'prep'),\n",
       " ('avoir', 'v'),\n",
       " ('une', 'det'),\n",
       " ('intervention', 'nc'),\n",
       " ('pour', 'prep'),\n",
       " ('vous', 'pro'),\n",
       " ('retirer', 'v'),\n",
       " ('un', 'det'),\n",
       " ('caillot', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('sang', 'nc'),\n",
       " ('dans', 'prep'),\n",
       " ('un', 'det'),\n",
       " ('vaisseau', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('cerveau', 'nc'),\n",
       " ('cette', 'pro'),\n",
       " ('fiche', 'nc'),\n",
       " ('décrit', 'v'),\n",
       " ('comment', 'adv'),\n",
       " ('cela', 'pro'),\n",
       " ('se', 'pro'),\n",
       " ('passe', 'v'),\n",
       " ('et', 'csu'),\n",
       " ('ce', 'pro'),\n",
       " ('qu', 'nc'),\n",
       " ('il', 'pro'),\n",
       " ('est', 'v'),\n",
       " ('important', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('savoir', 'v'),\n",
       " ('chum', 'nc'),\n",
       " ('patient', 'adj'),\n",
       " ('santé', 'nc'),\n",
       " ('neurologie', 'nc'),\n",
       " ('avc', 'adj'),\n",
       " ('accident', 'nc'),\n",
       " ('vasculaire', 'adj'),\n",
       " ('cérébral', 'adj'),\n",
       " ('ischémique', 'nc'),\n",
       " ('aigu', 'adj'),\n",
       " ('traitement', 'nc'),\n",
       " ('thrombectomie', 'nc'),\n",
       " ('endovasculaire', 'adj'),\n",
       " ('caillot', 'nc'),\n",
       " ('vaisseaux', 'nc'),\n",
       " ('sanguins', 'adj'),\n",
       " ('health', 'nc'),\n",
       " ('neurology', 'adj'),\n",
       " ('acute', 'v'),\n",
       " ('ischemic', 'nc'),\n",
       " ('stroke', 'adj'),\n",
       " ('ais', 'nc'),\n",
       " ('endovascular', 'adj'),\n",
       " ('thrombectomy', 'nc'),\n",
       " ('blood', 'adj'),\n",
       " ('clot', 'adj'),\n",
       " ('brain', 'nc'),\n",
       " ('vessel', 'adj'),\n",
       " ('voir', 'v'),\n",
       " ('la', 'det'),\n",
       " ('fiche', 'nc'),\n",
       " ('recherche', 'v'),\n",
       " ('rechercher', 'v'),\n",
       " ('prendre', 'v'),\n",
       " ('rendez', 'v'),\n",
       " ('vous', 'pro'),\n",
       " ('centre', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('prélèvement', 'nc'),\n",
       " ('guide', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('votre', 'det'),\n",
       " ('séjour', 'nc'),\n",
       " ('plan', 'adj'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('pour', 'prep'),\n",
       " ('vous', 'pro'),\n",
       " ('retrouver', 'v'),\n",
       " ('dans', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('hôpital', 'nc'),\n",
       " ('avant', 'prep'),\n",
       " ('de', 'prep'),\n",
       " ('vous', 'pro'),\n",
       " ('rendre', 'v'),\n",
       " ('à', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('urgence', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('est', 'v'),\n",
       " ('affilié', 'v'),\n",
       " ('à', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'adj'),\n",
       " ('portail', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('réseau', 'nc'),\n",
       " ('québécois', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('la', 'det'),\n",
       " ('télésanté', 'adj'),\n",
       " ('offre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('formations', 'nc'),\n",
       " ('laboratoires', 'nc'),\n",
       " ('fondation', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('bénévolat', 'nc'),\n",
       " ('bibliothèque', 'nc'),\n",
       " ('comité', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('usagers', 'adj'),\n",
       " ('commissaire', 'nc'),\n",
       " ('local', 'adj'),\n",
       " ('aux', 'prep'),\n",
       " ('plaintes', 'nc'),\n",
       " ('politique', 'adj'),\n",
       " (\"d'\", 'prep'),\n",
       " ('approvisionnement', 'nc'),\n",
       " ('regroupement', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('retraités', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('ruisss', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('confidentialité', 'nc'),\n",
       " ('avertissement', 'nc'),\n",
       " ('chum', 'nc'),\n",
       " ('navigation', 'nc'),\n",
       " ('patients', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('enseignement', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('académie', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('nouvelles', 'adj'),\n",
       " ('carrières', 'nc'),\n",
       " ('english', 'adj'),\n",
       " ('menu', 'adj'),\n",
       " ('sub', 'nc'),\n",
       " ('haut', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('cardiométabolique', 'adj'),\n",
       " ('vous', 'pro'),\n",
       " (\"n'\", 'adv'),\n",
       " ('êtes', 'v'),\n",
       " ('pas', 'adv'),\n",
       " ('autorisé', 'v'),\n",
       " ('e', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('accéder', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('cette', 'pro'),\n",
       " ('page', 'nc'),\n",
       " ('recherche', 'v'),\n",
       " ('rechercher', 'v'),\n",
       " ('prendre', 'v'),\n",
       " ('rendez', 'v'),\n",
       " ('vous', 'pro'),\n",
       " ('centre', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('prélèvement', 'nc'),\n",
       " ('guide', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('votre', 'det'),\n",
       " ('séjour', 'nc'),\n",
       " ('plan', 'adj'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('pour', 'prep'),\n",
       " ('vous', 'pro'),\n",
       " ('retrouver', 'v'),\n",
       " ('dans', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('hôpital', 'nc'),\n",
       " ('avant', 'prep'),\n",
       " ('de', 'prep'),\n",
       " ('vous', 'pro'),\n",
       " ('rendre', 'v'),\n",
       " ('à', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('urgence', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('est', 'v'),\n",
       " ('affilié', 'v'),\n",
       " ('à', 'prep'),\n",
       " (\"l'\", 'det'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'adj'),\n",
       " ('portail', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('réseau', 'nc'),\n",
       " ('québécois', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('la', 'det'),\n",
       " ('télésanté', 'adj'),\n",
       " ('offre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('formations', 'nc'),\n",
       " ('laboratoires', 'nc'),\n",
       " ('fondation', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('bénévolat', 'nc'),\n",
       " ('bibliothèque', 'nc'),\n",
       " ('comité', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('usagers', 'adj'),\n",
       " ('commissaire', 'nc'),\n",
       " ('local', 'adj'),\n",
       " ('aux', 'prep'),\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574866fe",
   "metadata": {},
   "source": [
    "### **Lemmatisation** (FrenchLefffLemmatizer)\n",
    "\n",
    "https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a494e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41c95983",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = FrenchLefffLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f002566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "for term in tagged:\n",
    "    term_l = []\n",
    "    if lemmatizer.lemmatize(term[0], term[1]) == []:\n",
    "        term_l = (lemmatizer.lemmatize(term[0]), term[1])\n",
    "    \n",
    "    elif type(lemmatizer.lemmatize(term[0], term[1])) == str:\n",
    "        term_l  = (lemmatizer.lemmatize(term[0], term[1]), term[1])\n",
    "\n",
    "    else:\n",
    "        term_l = tuple(lemmatizer.lemmatize(term[0], term[1])[0])\n",
    "    \n",
    "    lemmas.append(term_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59445403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jamal', 'adj'),\n",
       " ('rahima', 'nc'),\n",
       " ('chum', 'nc'),\n",
       " ('navigation', 'nc'),\n",
       " ('patient', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('enseignement', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('académie', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('nouveau', 'adj'),\n",
       " ('carrière', 'nc'),\n",
       " ('english', 'adj'),\n",
       " ('menu', 'adj'),\n",
       " ('sub', 'nc'),\n",
       " ('haut', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('chercheur', 'adj'),\n",
       " ('jamal', 'adj'),\n",
       " ('rahima', 'v'),\n",
       " ('m', 'nc'),\n",
       " ('d', 'v'),\n",
       " ('b', 'nc'),\n",
       " ('sc', 'adj'),\n",
       " ('frcpc', 'nc'),\n",
       " ('chercheur', 'adj'),\n",
       " ('investigateur', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('axe', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('cancer', 'nc'),\n",
       " ('directeur', 'adj'),\n",
       " ('médical', 'adj'),\n",
       " ('unité', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('innovation', 'nc'),\n",
       " ('thérapeutique', 'adj'),\n",
       " ('crchum', 'nc'),\n",
       " ('professeure', 'v'),\n",
       " ('adjoindre', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('clinique', 'adj'),\n",
       " ('département', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('médecine', 'nc'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'nc'),\n",
       " ('coordonné', 'adj'),\n",
       " ('rahima', 'v'),\n",
       " ('jamal', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('ssss', 'adj'),\n",
       " ('gouv', 'adj'),\n",
       " ('qc', 'nc'),\n",
       " ('ca', 'v'),\n",
       " ('poste', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('patient', 'nc'),\n",
       " ('qui', 'pro'),\n",
       " ('avoir', 'v'),\n",
       " ('besoin', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('assistance', 'nc'),\n",
       " ('immédiat', 'adj'),\n",
       " ('ne', 'adv'),\n",
       " ('devoir', 'v'),\n",
       " ('pas', 'adv'),\n",
       " ('communiquer', 'v'),\n",
       " ('directement', 'adv'),\n",
       " ('avec', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('chercheur', 'nc'),\n",
       " ('il', 'pro'),\n",
       " ('devoir', 'v'),\n",
       " ('plutôt', 'adv'),\n",
       " ('appeler', 'v'),\n",
       " ('le', 'det'),\n",
       " ('cabinet', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('médecin', 'nc'),\n",
       " ('ou', 'csu'),\n",
       " ('prendre', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('autre', 'adj'),\n",
       " ('mesure', 'nc'),\n",
       " ('approprier', 'v'),\n",
       " ('comme', 'csu'),\n",
       " ('se', 'pro'),\n",
       " ('rendre', 'v'),\n",
       " ('au', 'prep'),\n",
       " ('service', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('urgence', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('plus', 'adv'),\n",
       " ('proche', 'adj'),\n",
       " ('mot', 'nc'),\n",
       " ('clé', 'nc'),\n",
       " ('hémato', 'adj'),\n",
       " ('oncologie', 'nc'),\n",
       " ('étude', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('précoce', 'adj'),\n",
       " ('recherche', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('intérêt', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('mélanome', 'nc'),\n",
       " ('étude', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('phase', 'nc'),\n",
       " ('i', 'adj'),\n",
       " ('et', 'csu'),\n",
       " ('ii', 'adj'),\n",
       " ('publication', 'nc'),\n",
       " ('publication', 'nc'),\n",
       " ('indexer', 'v'),\n",
       " ('sur', 'prep'),\n",
       " ('pubmed', 'adj'),\n",
       " ('publication', 'nc'),\n",
       " ('indexer', 'v'),\n",
       " ('sur', 'prep'),\n",
       " ('researchgate', 'nc'),\n",
       " ('nouveau', 'adj'),\n",
       " ('recherche', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('précoce', 'adj'),\n",
       " ('au', 'prep'),\n",
       " ('québec', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('crchum', 'nc'),\n",
       " ('à', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('avant', 'prep'),\n",
       " ('scène', 'nc'),\n",
       " ('recherche', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('précoce', 'adj'),\n",
       " ('son', 'det'),\n",
       " ('unité', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('innovation', 'nc'),\n",
       " ('thérapeutique', 'adj'),\n",
       " ('en', 'prep'),\n",
       " ('orbite', 'nc'),\n",
       " ('nomination', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('rahima', 'nc'),\n",
       " ('jamal', 'adj'),\n",
       " ('comme', 'csu'),\n",
       " ('responsable', 'adj'),\n",
       " ('médical', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('unité', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('innovation', 'nc'),\n",
       " ('thérapeutique', 'adj'),\n",
       " ('greffer', 'v'),\n",
       " ('fécal', 'adj'),\n",
       " ('et', 'csu'),\n",
       " ('immunothérapie', 'nc'),\n",
       " ('un', 'det'),\n",
       " ('cocktail', 'nc'),\n",
       " ('gagner', 'v'),\n",
       " ('pour', 'prep'),\n",
       " ('vaincre', 'v'),\n",
       " ('le', 'det'),\n",
       " ('mélanome', 'nc'),\n",
       " ('rechercher', 'v'),\n",
       " ('rechercher', 'v'),\n",
       " ('média', 'nc'),\n",
       " ('social', 'adj'),\n",
       " ('crchum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('être', 'v'),\n",
       " ('affilier', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'adj'),\n",
       " ('portail', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('réseau', 'nc'),\n",
       " ('québécois', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('télésanté', 'adj'),\n",
       " ('offre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('formation', 'nc'),\n",
       " ('laboratoire', 'nc'),\n",
       " ('fondation', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('bénévolat', 'nc'),\n",
       " ('bibliothèque', 'nc'),\n",
       " ('comité', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('usager', 'adj'),\n",
       " ('commissaire', 'nc'),\n",
       " ('local', 'adj'),\n",
       " ('aux', 'prep'),\n",
       " ('plainte', 'nc'),\n",
       " ('politique', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('approvisionnement', 'nc'),\n",
       " ('regroupement', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('retraité', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('ruisss', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('confidentialité', 'nc'),\n",
       " ('avertissement', 'nc'),\n",
       " ('recherche', 'nc'),\n",
       " ('en', 'prep'),\n",
       " ('oncologie', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('précision', 'nc'),\n",
       " ('million', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('pour', 'prep'),\n",
       " ('un', 'det'),\n",
       " ('équipe', 'nc'),\n",
       " ('codiriger', 'v'),\n",
       " ('par', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('dre', 'adj'),\n",
       " ('diane', 'nc'),\n",
       " ('provencher', 'nc'),\n",
       " ('chum', 'nc'),\n",
       " ('navigation', 'nc'),\n",
       " ('patient', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('enseignement', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('académie', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('nouveau', 'adj'),\n",
       " ('carrière', 'nc'),\n",
       " ('menu', 'adj'),\n",
       " ('sub', 'nc'),\n",
       " ('haut', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('nouveau', 'adj'),\n",
       " ('recherche', 'nc'),\n",
       " ('en', 'prep'),\n",
       " ('oncologie', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('précision', 'nc'),\n",
       " ('million', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('pour', 'prep'),\n",
       " ('un', 'det'),\n",
       " ('équipe', 'nc'),\n",
       " ('codiriger', 'v'),\n",
       " ('par', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('dre', 'adj'),\n",
       " ('diane', 'nc'),\n",
       " ('provencher', 'nc'),\n",
       " ('juillet', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('équipe', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('mener', 'v'),\n",
       " ('par', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('d', 'nc'),\n",
       " ('re', 'v'),\n",
       " ('diane', 'nc'),\n",
       " ('provencher', 'v'),\n",
       " ('et', 'csu'),\n",
       " ('le', 'det'),\n",
       " ('d', 'nc'),\n",
       " ('re', 'v'),\n",
       " ('helen', 'adj'),\n",
       " ('mackay', 'nc'),\n",
       " ('sunnybrook', 'adj'),\n",
       " ('health', 'nc'),\n",
       " ('science', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('venir', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('recevoir', 'v'),\n",
       " ('un', 'det'),\n",
       " ('million', 'nc'),\n",
       " ('afin', 'csu'),\n",
       " ('de', 'prep'),\n",
       " ('évaluer', 'v'),\n",
       " ('un', 'det'),\n",
       " ('nouveau', 'adj'),\n",
       " ('combinaison', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('traitement', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('cancer', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('ovaire', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('du', 'prep'),\n",
       " ('cancer', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('sein', 'nc'),\n",
       " ('accorder', 'v'),\n",
       " ('par', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('organisme', 'nc'),\n",
       " ('à', 'prep'),\n",
       " ('but', 'nc'),\n",
       " ('non', 'adv'),\n",
       " ('lucratif', 'adj'),\n",
       " ('exactis', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('ce', 'pro'),\n",
       " ('financement', 'nc'),\n",
       " ('permettre', 'v'),\n",
       " ('le', 'det'),\n",
       " ('tenue', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('un', 'det'),\n",
       " ('essai', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('multicentrique', 'adj'),\n",
       " ('dans', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('réseau', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('exactis', 'adj'),\n",
       " ('qui', 'pro'),\n",
       " ('regrouper', 'v'),\n",
       " ('onze', '-'),\n",
       " ('grand', 'adj'),\n",
       " ('établissement', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('soin', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('cancer', 'nc'),\n",
       " ('au', 'prep'),\n",
       " ('canada', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('essai', 'nc'),\n",
       " ('découler', 'v'),\n",
       " ('directement', 'adv'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('mener', 'v'),\n",
       " ('dans', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('laboratoire', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('son', 'det'),\n",
       " ('masson', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('de', 'prep'),\n",
       " ('francis', 'nc'),\n",
       " ('rodier', 'adj'),\n",
       " ('crchum', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('de', 'prep'),\n",
       " ('david', 'adj'),\n",
       " ('andrews', 'nc'),\n",
       " ('university', 'adj'),\n",
       " ('of', 'adj'),\n",
       " ('toronto', 'nc'),\n",
       " ('ces', 'pro'),\n",
       " ('dernier', 'nc'),\n",
       " ('être', 'v'),\n",
       " ('le', 'det'),\n",
       " ('responsable', 'adj'),\n",
       " ('scientifique', 'adj'),\n",
       " ('du', 'prep'),\n",
       " ('projet', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('espérer', 'v'),\n",
       " ('ouvrir', 'v'),\n",
       " ('le', 'det'),\n",
       " ('voie', 'nc'),\n",
       " ('à', 'prep'),\n",
       " ('un', 'det'),\n",
       " ('nouveau', 'adj'),\n",
       " ('approche', 'nc'),\n",
       " ('pour', 'prep'),\n",
       " ('personnaliser', 'v'),\n",
       " ('le', 'det'),\n",
       " ('traitement', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('femme', 'nc'),\n",
       " ('atteindre', 'v'),\n",
       " ('des', 'prep'),\n",
       " ('cancer', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('sein', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('ovaire', 'nc'),\n",
       " ('un', 'det'),\n",
       " ('comité', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('expert', 'nc'),\n",
       " ('international', 'adj'),\n",
       " ('avoir', 'v'),\n",
       " ('sélectionner', 'v'),\n",
       " ('le', 'det'),\n",
       " ('projet', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('clinique', 'adj'),\n",
       " ('des', 'prep'),\n",
       " ('d', 'nc'),\n",
       " ('rs', 'v'),\n",
       " ('provencher', 'v'),\n",
       " ('et', 'csu'),\n",
       " ('mackay', 'nc'),\n",
       " ('parmi', 'prep'),\n",
       " ('des', 'prep'),\n",
       " ('demande', 'nc'),\n",
       " ('provenir', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('tout', 'pro'),\n",
       " ('le', 'det'),\n",
       " ('pays', 'nc'),\n",
       " ('dans', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('domaine', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('médecine', 'nc'),\n",
       " ('personnaliser', 'v'),\n",
       " ('qu', 'v'),\n",
       " ('lui', 'pro'),\n",
       " ('être', 'v'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('sunnybrook', 'nc'),\n",
       " ('health', 'nc'),\n",
       " ('science', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('hôpital', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('ottawa', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('hôpital', 'nc'),\n",
       " ('général', 'adj'),\n",
       " ('juif', 'adj'),\n",
       " ('ou', 'csu'),\n",
       " ('du', 'prep'),\n",
       " ('london', 'nc'),\n",
       " ('health', 'nc'),\n",
       " ('science', 'nc'),\n",
       " ('centrer', 'v'),\n",
       " ('le', 'det'),\n",
       " ('patient', 'nc'),\n",
       " ('atteindre', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('un', 'det'),\n",
       " ('carcinome', 'nc'),\n",
       " ('séreux', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('haut', 'adj'),\n",
       " ('grade', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('ovaire', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('de', 'prep'),\n",
       " ('un', 'det'),\n",
       " ('cancer', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('sein', 'nc'),\n",
       " ('triple', 'adj'),\n",
       " ('négatif', 'adj'),\n",
       " ('et', 'csu'),\n",
       " ('avoir', 'v'),\n",
       " ('peu', 'adv'),\n",
       " ('de', 'prep'),\n",
       " ('option', 'nc'),\n",
       " ('thérapeutique', 'adj'),\n",
       " ('pouvoir', 'v'),\n",
       " ('participer', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('cet', 'pro'),\n",
       " ('essai', 'nc'),\n",
       " ('facebook', 'nc'),\n",
       " ('twitter', 'v'),\n",
       " ('linkedin', 'adj'),\n",
       " ('print', 'nc'),\n",
       " ('rechercher', 'v'),\n",
       " ('rechercher', 'v'),\n",
       " ('média', 'nc'),\n",
       " ('social', 'adj'),\n",
       " ('crchum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('être', 'v'),\n",
       " ('affilier', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'adj'),\n",
       " ('portail', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('réseau', 'nc'),\n",
       " ('québécois', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('télésanté', 'adj'),\n",
       " ('offre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('formation', 'nc'),\n",
       " ('laboratoire', 'nc'),\n",
       " ('fondation', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('bénévolat', 'nc'),\n",
       " ('bibliothèque', 'nc'),\n",
       " ('comité', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('usager', 'adj'),\n",
       " ('commissaire', 'nc'),\n",
       " ('local', 'adj'),\n",
       " ('aux', 'prep'),\n",
       " ('plainte', 'nc'),\n",
       " ('politique', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('approvisionnement', 'nc'),\n",
       " ('regroupement', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('retraité', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('ruisss', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('confidentialité', 'nc'),\n",
       " ('avertissement', 'nc'),\n",
       " ('leclerc', 'nc'),\n",
       " ('isabelle', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('navigation', 'nc'),\n",
       " ('patient', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('enseignement', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('académie', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('nouveau', 'adj'),\n",
       " ('carrière', 'nc'),\n",
       " ('english', 'adj'),\n",
       " ('menu', 'adj'),\n",
       " ('sub', 'nc'),\n",
       " ('haut', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('chercheur', 'adj'),\n",
       " ('leclerc', 'nc'),\n",
       " ('isabelle', 'adj'),\n",
       " ('chercheur', 'adj'),\n",
       " ('régulier', 'adj'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('axe', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('cardiométabolique', 'adj'),\n",
       " ('professeure', 'nc'),\n",
       " ('titulaire', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('clinique', 'adj'),\n",
       " ('département', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('médecine', 'nc'),\n",
       " ('faculté', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('médecine', 'nc'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'nc'),\n",
       " ('coordonner', 'v'),\n",
       " ('isabelle', 'adj'),\n",
       " ('leclerc', 'nc'),\n",
       " ('chum', 'nc'),\n",
       " ('ssss', 'adj'),\n",
       " ('gouv', 'adj'),\n",
       " ('qc', 'nc'),\n",
       " ('ca', 'v'),\n",
       " ('poste', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('patient', 'nc'),\n",
       " ('qui', 'pro'),\n",
       " ('avoir', 'v'),\n",
       " ('besoin', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('assistance', 'nc'),\n",
       " ('immédiat', 'adj'),\n",
       " ('ne', 'adv'),\n",
       " ('devoir', 'v'),\n",
       " ('pas', 'adv'),\n",
       " ('communiquer', 'v'),\n",
       " ('directement', 'adv'),\n",
       " ('avec', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('chercheur', 'nc'),\n",
       " ('il', 'pro'),\n",
       " ('devoir', 'v'),\n",
       " ('plutôt', 'adv'),\n",
       " ('appeler', 'v'),\n",
       " ('le', 'det'),\n",
       " ('cabinet', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('médecin', 'nc'),\n",
       " ('ou', 'csu'),\n",
       " ('prendre', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('autre', 'adj'),\n",
       " ('mesure', 'nc'),\n",
       " ('approprier', 'v'),\n",
       " ('comme', 'csu'),\n",
       " ('se', 'pro'),\n",
       " ('rendre', 'v'),\n",
       " ('au', 'prep'),\n",
       " ('service', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('urgence', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('plus', 'adv'),\n",
       " ('proche', 'adj'),\n",
       " ('publication', 'nc'),\n",
       " ('pubmed', 'adj'),\n",
       " ('rechercher', 'v'),\n",
       " ('rechercher', 'v'),\n",
       " ('média', 'nc'),\n",
       " ('social', 'adj'),\n",
       " ('crchum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('être', 'v'),\n",
       " ('affilier', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'adj'),\n",
       " ('portail', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('réseau', 'nc'),\n",
       " ('québécois', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('télésanté', 'adj'),\n",
       " ('offre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('formation', 'nc'),\n",
       " ('laboratoire', 'nc'),\n",
       " ('fondation', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('bénévolat', 'nc'),\n",
       " ('bibliothèque', 'nc'),\n",
       " ('comité', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('usager', 'adj'),\n",
       " ('commissaire', 'nc'),\n",
       " ('local', 'adj'),\n",
       " ('aux', 'prep'),\n",
       " ('plainte', 'nc'),\n",
       " ('politique', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('approvisionnement', 'nc'),\n",
       " ('regroupement', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('retraité', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('ruisss', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('confidentialité', 'nc'),\n",
       " ('avertissement', 'nc'),\n",
       " ('traiter', 'v'),\n",
       " ('un', 'det'),\n",
       " ('avc', 'nc'),\n",
       " ('par', 'prep'),\n",
       " ('un', 'det'),\n",
       " ('intervention', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('thrombectomie', 'nc'),\n",
       " ('endovasculaire', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('navigation', 'nc'),\n",
       " ('patient', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('enseignement', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('académie', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('nouveau', 'adj'),\n",
       " ('carrière', 'nc'),\n",
       " ('english', 'adj'),\n",
       " ('menu', 'adj'),\n",
       " ('sub', 'nc'),\n",
       " ('haut', 'adv'),\n",
       " ('répertoire', 'nc'),\n",
       " ('traiter', 'v'),\n",
       " ('un', 'det'),\n",
       " ('avc', 'nc'),\n",
       " ('par', 'prep'),\n",
       " ('un', 'det'),\n",
       " ('intervention', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('thrombectomie', 'nc'),\n",
       " ('endovasculaire', 'adj'),\n",
       " ('lui', 'pro'),\n",
       " ('aller', 'v'),\n",
       " ('bientôt', 'adv'),\n",
       " ('avoir', 'v'),\n",
       " ('ou', 'csu'),\n",
       " ('lui', 'pro'),\n",
       " ('venir', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('avoir', 'v'),\n",
       " ('un', 'det'),\n",
       " ('intervention', 'nc'),\n",
       " ('pour', 'prep'),\n",
       " ('lui', 'pro'),\n",
       " ('retirer', 'v'),\n",
       " ('un', 'det'),\n",
       " ('caillot', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('sang', 'nc'),\n",
       " ('dans', 'prep'),\n",
       " ('un', 'det'),\n",
       " ('vaisseau', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('cerveau', 'nc'),\n",
       " ('cette', 'pro'),\n",
       " ('fiche', 'nc'),\n",
       " ('décrire', 'v'),\n",
       " ('comment', 'adv'),\n",
       " ('cela', 'pro'),\n",
       " ('se', 'pro'),\n",
       " ('passer', 'v'),\n",
       " ('et', 'csu'),\n",
       " ('ce', 'pro'),\n",
       " ('qu', 'nc'),\n",
       " ('il', 'pro'),\n",
       " ('être', 'v'),\n",
       " ('important', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('savoir', 'v'),\n",
       " ('chum', 'nc'),\n",
       " ('patient', 'adj'),\n",
       " ('santé', 'nc'),\n",
       " ('neurologie', 'nc'),\n",
       " ('avc', 'adj'),\n",
       " ('accident', 'nc'),\n",
       " ('vasculaire', 'adj'),\n",
       " ('cérébral', 'adj'),\n",
       " ('ischémique', 'nc'),\n",
       " ('aigu', 'adj'),\n",
       " ('traitement', 'nc'),\n",
       " ('thrombectomie', 'nc'),\n",
       " ('endovasculaire', 'adj'),\n",
       " ('caillot', 'nc'),\n",
       " ('vaisseau', 'nc'),\n",
       " ('sanguin', 'adj'),\n",
       " ('health', 'nc'),\n",
       " ('neurology', 'adj'),\n",
       " ('acute', 'v'),\n",
       " ('ischemic', 'nc'),\n",
       " ('stroke', 'adj'),\n",
       " ('ais', 'nc'),\n",
       " ('endovascular', 'adj'),\n",
       " ('thrombectomy', 'nc'),\n",
       " ('blood', 'adj'),\n",
       " ('clot', 'adj'),\n",
       " ('brain', 'nc'),\n",
       " ('vessel', 'adj'),\n",
       " ('voir', 'v'),\n",
       " ('le', 'det'),\n",
       " ('fiche', 'nc'),\n",
       " ('rechercher', 'v'),\n",
       " ('rechercher', 'v'),\n",
       " ('prendre', 'v'),\n",
       " ('rendre', 'v'),\n",
       " ('lui', 'pro'),\n",
       " ('centrer', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('prélèvement', 'nc'),\n",
       " ('guider', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('son', 'det'),\n",
       " ('séjour', 'nc'),\n",
       " ('plan', 'adj'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('pour', 'prep'),\n",
       " ('lui', 'pro'),\n",
       " ('retrouver', 'v'),\n",
       " ('dans', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('hôpital', 'nc'),\n",
       " ('avant', 'prep'),\n",
       " ('de', 'prep'),\n",
       " ('lui', 'pro'),\n",
       " ('rendre', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('urgence', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('être', 'v'),\n",
       " ('affilier', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'adj'),\n",
       " ('portail', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('réseau', 'nc'),\n",
       " ('québécois', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('télésanté', 'adj'),\n",
       " ('offre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('formation', 'nc'),\n",
       " ('laboratoire', 'nc'),\n",
       " ('fondation', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('bénévolat', 'nc'),\n",
       " ('bibliothèque', 'nc'),\n",
       " ('comité', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('usager', 'adj'),\n",
       " ('commissaire', 'nc'),\n",
       " ('local', 'adj'),\n",
       " ('aux', 'prep'),\n",
       " ('plainte', 'nc'),\n",
       " ('politique', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('approvisionnement', 'nc'),\n",
       " ('regroupement', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('retraité', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('ruisss', 'adj'),\n",
       " ('chum', 'nc'),\n",
       " ('confidentialité', 'nc'),\n",
       " ('avertissement', 'nc'),\n",
       " ('chum', 'nc'),\n",
       " ('navigation', 'nc'),\n",
       " ('patient', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('enseignement', 'nc'),\n",
       " ('et', 'csu'),\n",
       " ('académie', 'nc'),\n",
       " ('centre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('recherche', 'nc'),\n",
       " ('innovation', 'nc'),\n",
       " ('nouveau', 'adj'),\n",
       " ('carrière', 'nc'),\n",
       " ('english', 'adj'),\n",
       " ('menu', 'adj'),\n",
       " ('sub', 'nc'),\n",
       " ('haut', 'adj'),\n",
       " ('répertoire', 'nc'),\n",
       " ('cardiométabolique', 'adj'),\n",
       " ('lui', 'pro'),\n",
       " (\"n'\", 'adv'),\n",
       " ('être', 'v'),\n",
       " ('pas', 'adv'),\n",
       " ('autoriser', 'v'),\n",
       " ('e', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('accéder', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('cette', 'pro'),\n",
       " ('page', 'nc'),\n",
       " ('rechercher', 'v'),\n",
       " ('rechercher', 'v'),\n",
       " ('prendre', 'v'),\n",
       " ('rendre', 'v'),\n",
       " ('lui', 'pro'),\n",
       " ('centrer', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('prélèvement', 'nc'),\n",
       " ('guider', 'v'),\n",
       " ('de', 'prep'),\n",
       " ('son', 'det'),\n",
       " ('séjour', 'nc'),\n",
       " ('plan', 'adj'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('pour', 'prep'),\n",
       " ('lui', 'pro'),\n",
       " ('retrouver', 'v'),\n",
       " ('dans', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('hôpital', 'nc'),\n",
       " ('avant', 'prep'),\n",
       " ('de', 'prep'),\n",
       " ('lui', 'pro'),\n",
       " ('rendre', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('urgence', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('le', 'det'),\n",
       " ('chum', 'nc'),\n",
       " ('être', 'v'),\n",
       " ('affilier', 'v'),\n",
       " ('à', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('université', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('montréal', 'adj'),\n",
       " ('portail', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('réseau', 'nc'),\n",
       " ('québécois', 'adj'),\n",
       " ('de', 'prep'),\n",
       " ('le', 'det'),\n",
       " ('télésanté', 'adj'),\n",
       " ('offre', 'nc'),\n",
       " ('de', 'prep'),\n",
       " ('formation', 'nc'),\n",
       " ('laboratoire', 'nc'),\n",
       " ('fondation', 'nc'),\n",
       " ('du', 'prep'),\n",
       " ('chum', 'nc'),\n",
       " ('bénévolat', 'nc'),\n",
       " ('bibliothèque', 'nc'),\n",
       " ('comité', 'nc'),\n",
       " ('des', 'prep'),\n",
       " ('usager', 'adj'),\n",
       " ('commissaire', 'nc'),\n",
       " ('local', 'adj'),\n",
       " ('aux', 'prep'),\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab9f5e",
   "metadata": {},
   "source": [
    "### **Filtrage** (antidictionnaire)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d96dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer l'antidictionnaire pour filtrer les données\n",
    "\n",
    "# Stopwords lemmatisés\n",
    "file_path = '../04-filtrage/stopwords_lemmatized.txt'\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    stopwords_lemmatized = [w.strip('\\n').lower() for w in f.readlines()]\n",
    "\n",
    "# Stopwords fréquents en français (non lemmatisés)\n",
    "file_path = \"../04-filtrage/stopwords.txt\"\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    stopwords = [t.lower().strip('\\n') for t in f.readlines()]\n",
    "\n",
    "\n",
    "# Stopwords fréquents en anglais (non lemmatisés)\n",
    "file_path = '../04-filtrage/stop_words_english.txt'\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    stopwords += [t.lower().strip('\\n') for t in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b5f4d",
   "metadata": {},
   "source": [
    "### **Collocations / Phrases / N-Grammes (MWE)**\n",
    "https://www.kaggle.com/code/alvations/n-gram-language-model-with-nltk/notebook  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4fc7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import everygrams\n",
    "ngrammes = list(everygrams(tagged, min_len=2, max_len=5))\n",
    "ngrammes_lemmatized = list(everygrams(lemmas, min_len=2, max_len=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18ecac95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant filtrage, on a 3127190 ngrammes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Avant filtrage, on a {} ngrammes.\".format(len(ngrammes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1d405",
   "metadata": {},
   "source": [
    "### **Filtrage (N-grammes)**\n",
    "\n",
    "On retire les n-grammes qui apparaissent moins de 30 fois dans tout le corpus ou qui débutent ou terminent par :\n",
    "- un stopword\n",
    "- un mot de 1 lettre ou moins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3d97d",
   "metadata": {},
   "source": [
    "Pour le reste du traitement, on arrête de considérer les frontières entre les phrases et entre les documents (nos ngrammes les respectent donc on n'en a plus besoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0ecd6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patterns(ngrammes):\n",
    "    patterns = []\n",
    "\n",
    "    for ng in ngrammes:\n",
    "        phrase = []\n",
    "        pattern = []\n",
    "        for t in ng:\n",
    "            phrase.append(t[0]) # token\n",
    "            pattern.append(t[1]) # POS tag\n",
    "\n",
    "        patterns.append([phrase, pattern])\n",
    "        \n",
    "    return patterns\n",
    "\n",
    "phrases = extract_patterns(ngrammes)\n",
    "phrases_lemmatized = extract_patterns(ngrammes_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5ee6d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['jamal', 'rahima'], ['adj', 'nc']],\n",
       " [['jamal', 'rahima', 'chum'], ['adj', 'nc', 'nc']],\n",
       " [['jamal', 'rahima', 'chum', 'navigation'], ['adj', 'nc', 'nc', 'nc']],\n",
       " [['jamal', 'rahima', 'chum', 'navigation', 'patients'],\n",
       "  ['adj', 'nc', 'nc', 'nc', 'adj']],\n",
       " [['rahima', 'chum'], ['nc', 'nc']],\n",
       " [['rahima', 'chum', 'navigation'], ['nc', 'nc', 'nc']],\n",
       " [['rahima', 'chum', 'navigation', 'patients'], ['nc', 'nc', 'nc', 'adj']],\n",
       " [['rahima', 'chum', 'navigation', 'patients', 'répertoire'],\n",
       "  ['nc', 'nc', 'nc', 'adj', 'nc']],\n",
       " [['chum', 'navigation'], ['nc', 'nc']],\n",
       " [['chum', 'navigation', 'patients'], ['nc', 'nc', 'adj']],\n",
       " [['chum', 'navigation', 'patients', 'répertoire'], ['nc', 'nc', 'adj', 'nc']],\n",
       " [['chum', 'navigation', 'patients', 'répertoire', 'enseignement'],\n",
       "  ['nc', 'nc', 'adj', 'nc', 'nc']],\n",
       " [['navigation', 'patients'], ['nc', 'adj']],\n",
       " [['navigation', 'patients', 'répertoire'], ['nc', 'adj', 'nc']],\n",
       " [['navigation', 'patients', 'répertoire', 'enseignement'],\n",
       "  ['nc', 'adj', 'nc', 'nc']],\n",
       " [['navigation', 'patients', 'répertoire', 'enseignement', 'et'],\n",
       "  ['nc', 'adj', 'nc', 'nc', 'csu']],\n",
       " [['patients', 'répertoire'], ['adj', 'nc']],\n",
       " [['patients', 'répertoire', 'enseignement'], ['adj', 'nc', 'nc']],\n",
       " [['patients', 'répertoire', 'enseignement', 'et'],\n",
       "  ['adj', 'nc', 'nc', 'csu']],\n",
       " [['patients', 'répertoire', 'enseignement', 'et', 'académie'],\n",
       "  ['adj', 'nc', 'nc', 'csu', 'nc']]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b55a7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "freq = FreqDist([\" \".join(t[0]).replace(\"' \", \"'\") for t in phrases])\n",
    "freq_lemmatized = FreqDist([\" \".join(t[0]).replace(\"' \", \"'\") for t in phrases_lemmatized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cb2026f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'du chum': 8694, 'de la': 7543, 'de recherche': 6334, 'centre de': 5331, \"à l'\": 5163, 'le chum': 5065, \"de l'\": 4211, 'centre de recherche': 4044, 'de montréal': 3619, 'université de': 3437, ...})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a008d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrer_phrases(phrases, freq):\n",
    "        output = []\n",
    "        for term in phrases:\n",
    "                exp = \" \".join(term[0]).replace(\"' \", \"'\")\n",
    "                f = freq[exp]\n",
    "                \n",
    "                # f > x and - Si on veut filtrer par fréquence \n",
    "                if  not term[0][0] in stopwords and len(term[0][0]) > 2 \\\n",
    "                and not term[0][-1] in stopwords and len(term[0][-1]) > 2 : \n",
    "                        pattern = \" \".join(term[1])            \n",
    "                        output.append([exp, pattern, f])  \n",
    "                         \n",
    "        return output\n",
    "\n",
    "phrases = filtrer_phrases(phrases, freq)\n",
    "phrases_lemmatized = filtrer_phrases(phrases_lemmatized, freq_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3edd530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après filtrage, on a 718874 occurrences de ngrammes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Après filtrage, on a {} occurrences de ngrammes.\".format(len(phrases))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be52a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabCSV(phrases, titre):\n",
    "    base_path = '../04-filtrage/output/'\n",
    "    tab = DataFrame(phrases, columns= [\"Expression\", \"Structure syntaxique\", \"Fréquence\"]).drop_duplicates()\n",
    "    tab.sort_values([\"Fréquence\"], \n",
    "                        axis=0,\n",
    "                        ascending=[False], \n",
    "                        inplace=True)\n",
    "\n",
    "\n",
    "    file_path = path.join(base_path, acteur, acteur)\n",
    "    if sous_corpus:\n",
    "       file_path = path.join(base_path, acteur, tag, tag)\n",
    "    \n",
    "\n",
    "    Path(file_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    tab.to_csv(file_path + titre)\n",
    "\n",
    "    return tab.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3f79a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = tabCSV(phrases,'_n-grams.csv')\n",
    "phrases_lemmatized = tabCSV(phrases_lemmatized, '_n-grams-lemmatized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4acce1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après filtrage, on a 318189 ngrammes uniques.\n"
     ]
    }
   ],
   "source": [
    "print(\"Après filtrage, on a {} ngrammes uniques.\".format(len(phrases)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386aa5c",
   "metadata": {},
   "source": [
    "### **Filtrage (Patrons syntaxiques)**  \n",
    "Lossio-Ventura, J. A., Jonquet, C., Roche, M., & Teisseire, M. (2014). Biomedical Terminology Extraction : A new combination of Statistical and Web Mining Approaches. 421. https://hal-lirmm.ccsd.cnrs.fr/lirmm-01056598\n",
    "\n",
    "On veut aller extraire les structures syntaxiques les plus courantes dans les MeSH pour filtrer notre corpus selon celles-ci (inspiré de la méthodologie de l'article ci-dessus ; voir le Notebook *Mesh_extract.ipynb*). Pour ce faire, nous allons donc ne sélectionner que les ngrammes qui y correspondent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15945967",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../04-filtrage/mesh_patterns-fr.csv'\n",
    "\n",
    "with open (file_path, 'r') as f:\n",
    "    patterns = read_csv(f)\n",
    "    patterns = patterns['Structure'].tolist()[:100] # Pour prendre seulement les 50 structures syntaxiques les plus fréquentes dans les MeSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1e03045",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [t for t in phrases if t[1] in patterns]\n",
    "terms_lemmatized = [t for t in phrases_lemmatized if t[1] in patterns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4539e651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le filtrage syntaxique élimine environ 61 % des termes\n",
      "On avait 318189 bigrammes, on en a maintenant 122557.\n"
     ]
    }
   ],
   "source": [
    "print(\"Le filtrage syntaxique élimine environ {} % des termes\".format(round((len(phrases) - len(terms)) / len(phrases) * 100)))\n",
    "print(\"On avait {} bigrammes, \".format(len(phrases)) + \"on en a maintenant {}.\".format(len(terms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b74b50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_terms(liste_terms, titre):\n",
    "    file_path = '../04-filtrage/output/'\n",
    "    tab = pd.DataFrame(terms, columns= [\"Expression\", \"Structure syntaxique\", \"Fréquence\"]).drop_duplicates(subset='Expression', keep=\"last\")\n",
    "    tab.sort_values([\"Fréquence\"], \n",
    "                        axis=0,\n",
    "                        ascending=[False], \n",
    "                        inplace=True)\n",
    "\n",
    "    if sous_corpus:\n",
    "        file_path = path.join(file_path, acteur, tag, tag)\n",
    "\n",
    "    else :\n",
    "        file_path = path.join(file_path, acteur, acteur)\n",
    "\n",
    "                    \n",
    "    tab.to_csv(file_path + titre)\n",
    "\n",
    "extract_terms(terms, '_terms.csv')\n",
    "extract_terms(terms_lemmatized, '_terms-lemmatized.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1baa06e",
   "metadata": {},
   "source": [
    "### **Filtrage (Collocations statistiquement significatives)** Log-Likelihood Ratio\n",
    "\n",
    "[Notebook - Collocation extraction methodologies compared](https://notebooks.githubusercontent.com/view/ipynb?azure_maps_enabled=false&browser=chrome&color_mode=auto&commit=33868e847376764d7733cd958986c88dedfaec97&device=unknown&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f746f64642d636f6f6b2f4d4c2d596f752d43616e2d5573652f333338363865383437333736373634643737333363643935383938366338386465646661656339372f70726f626162696c69737469635f6c616e67756167655f6d6f64656c696e672f636f6c6c6f636174696f6e5f65787472616374696f6e732e6970796e62&enterprise_enabled=false&logged_in=false&nwo=todd-cook%2FML-You-Can-Use&path=probabilistic_language_modeling%2Fcollocation_extractions.ipynb&platform=android&repository_id=167140788&repository_type=Repository&version=102)\n",
    "\n",
    "On applique un test d'hypothèse statistique aux n-grammes sur lesquels une probabilité a été mesurée (Log-likelihood ratio) - seuls les n-grammes dont le test est significatif seront conservés.\n",
    "On considère que l'apparition de ces collocations dans notre corpus n'est pas dûe au hasard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cc17f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood_ratio(c_prior, c_n, c_ngram, N):\n",
    "    \"\"\"\n",
    "    Compute the ratio of two hypotheses of likelihood and return the ratio.\n",
    "    The formula here and test verification values are taken from \n",
    "    Manning & Schūtze _Foundations of Statistical Natural Language Processing_ p.172-175\n",
    "    Parameters:\n",
    "    c_prior: count of word 1 if bigrams or count of [w1w2 .. w(n-1)] if ngram\n",
    "    c_n : count of word 2 if bigrams or count of wn if ngram\n",
    "    c12: count of bigram (w1, w2) if bigram or count of ngram if ngram\n",
    "    N: the number of words in the corpus\n",
    "    \"\"\"\n",
    "\n",
    "    p = c_n / N\n",
    "    p1 = c_ngram / c_prior\n",
    "    p2 = (c_n - c_ngram) / (N - c_prior)   \n",
    "    # We proactively trap a runtimeWarning: divide by zero encountered in log,\n",
    "    # which may occur with extreme collocations\n",
    "    import warnings\n",
    "    with warnings.catch_warnings(): # this will reset our filterwarnings setting\n",
    "        warnings.filterwarnings('error')\n",
    "        try:\n",
    "            return (np.log(binom.pmf(c_ngram, c_prior, p)) \n",
    "                    + np.log(binom.pmf(c_n - c_ngram, N - c_prior, p)) \n",
    "                    - np.log(binom.pmf(c_ngram, c_prior, p1) )\n",
    "                    - np.log(binom.pmf(c_n - c_ngram, N - c_prior, p2)))             \n",
    "        except Warning:\n",
    "            return np.inf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20e82354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Au départ, on a 122557 ngrammes.\n"
     ]
    }
   ],
   "source": [
    "len_prior = len(terms)\n",
    "print(\"Au départ, on a {} ngrammes.\".format(len_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2891d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import binom, chi2\n",
    "from nltk import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "544f5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour le calcul des probabilités, on a besoin de traiter séparément les ngrammes selon la valeur de n\n",
    "N = len(tokens)\n",
    "fd_ug = nltk.FreqDist(tokens)\n",
    "\n",
    "bg = [tuple(tokenizer_re.tokenize(term[0])) for term in terms if len(tokenizer_re.tokenize(term[0])) == 2] # Bigrammes\n",
    "fd_bg = nltk.FreqDist(bigrams(tokens)) # On calcule la distribution de fréquences à partir de tous les tokens pour éviter des divisions par zéro à l'étape suivante\n",
    "\n",
    "tg = [tuple(tokenizer_re.tokenize(term[0])) for term in terms if len(tokenizer_re.tokenize(term[0])) == 3] # Trigrammes\n",
    "fd_tg = nltk.FreqDist(trigrams(tokens)) # On calcule la distribution de fréquences à partir de tous les tokens pour éviter des divisions par zéro à l'étape suivante\n",
    "\n",
    "qg = [tuple(tokenizer_re.tokenize(term[0])) for term in terms if len(tokenizer_re.tokenize(term[0])) == 4] # Quadgrammes\n",
    "fd_qg = nltk.FreqDist(ngrams(tokens, n=4)) # On calcule la distribution de fréquences à partir de tous les tokens pour éviter des divisions par zéro à l'étape suivante\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28b3f1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici quelques bigrammes : [('moineau', 'chum'), ('support', 'circle'), ('rétroaction', 'personnalisée')]\n",
      "Voici quelques trigrammes : [('préventive', 'endocrinologie'), ('thérapeutiques', 'chum'), ('activité', 'neuronale'), ('questionnaires', 'psychométriques')]\n",
      "Voici quelques quadgrammes : [('chercheurs', 'ethier'), ('pratiques', 'chum')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Voici quelques bigrammes : \"+ str(random.sample(bg, 3)))\n",
    "print(\"Voici quelques trigrammes : \"+ str(random.sample(bg, 4)))\n",
    "print(\"Voici quelques quadgrammes : \"+ str(random.sample(bg, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ab3c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llr_bigrammes = []\n",
    "\n",
    "for b in set(bg):\n",
    "    c1 = fd_ug[b[0]]\n",
    "    c2 = fd_ug[b[1]]\n",
    "    c_ngram = fd_bg[b]\n",
    "\n",
    "    res = -2 * loglikelihood_ratio(c1, c2, c_ngram, N)\n",
    "    p = chi2.sf(res, 1) # 1 degrees of freedom\n",
    "\n",
    "    if p < 0.05 or (res == float('-inf')):\n",
    "        llr_bigrammes.append({'Collocation' : \" \".join(b).replace(\"' \", \"'\"), 'Fréquence' : c_ngram, 'LLR': res, 'p-value': p})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21e8c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llr_trigrammes = []\n",
    "\n",
    "for t in set(tg):\n",
    "    c_prior = fd_bg[t[:2]] # Antécédent = P(w1w2) (si on considère que P (w1w2w3) = P(w3) | P(w1w2)\n",
    "    c_n = fd_ug[t[2]]\n",
    "    c_ngram = fd_tg[t] \n",
    "\n",
    "    res = -2 * loglikelihood_ratio(c_prior, c_n, c_ngram, N)\n",
    "    p = chi2.sf(res, 1) # 1 degrees of freedom\n",
    "\n",
    "    if p < 0.05 or (res == float('-inf')):\n",
    "        llr_trigrammes.append({'Collocation' : \" \".join(t).replace(\"' \", \"'\"), 'Fréquence' : c_ngram, 'LLR': res, 'p-value': p})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3258121",
   "metadata": {},
   "outputs": [],
   "source": [
    "llr_quadgrammes = []\n",
    "\n",
    "for q in set(qg):\n",
    "    c_prior = fd_tg[q[:3]] # Antécédent = P(w1w2w3) si on considère que P (w1w2w3w4) = P(w4 | P(w1w2w3)\n",
    "    c_n = fd_ug[q[3]]\n",
    "    c_ngram = fd_qg[q]\n",
    "\n",
    "    res = -2 * loglikelihood_ratio(c_prior, c_n, c_ngram, N)\n",
    "    p = chi2.sf(res, 1) # 1 degrees of freedom\n",
    "\n",
    "    if p < 0.05 or (res == float('-inf')):\n",
    "        llr_quadgrammes.append({'Collocation' : \" \".join(q).replace(\"' \", \"'\"), 'Fréquence' : c_ngram, 'LLR': res, 'p-value': p})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74c08c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p1115145\\AppData\\Local\\Temp\\ipykernel_13212\\27556930.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df_bg.append(df_tg).append(df_qg)\n"
     ]
    }
   ],
   "source": [
    "df_bg = pd.DataFrame(llr_bigrammes)\n",
    "df_tg = pd.DataFrame(llr_trigrammes)\n",
    "df_qg = pd.DataFrame(llr_quadgrammes)\n",
    "\n",
    "df = df_bg.append(df_tg).append(df_qg)\n",
    "df.sort_values(['p-value'], \n",
    "            axis=0,\n",
    "            ascending=[True], \n",
    "            inplace=True)\n",
    "\n",
    "output_path = path.join('../04-filtrage/output/', acteur, acteur + '_significant-collocations.csv') \n",
    "df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847ef6e6",
   "metadata": {},
   "source": [
    "### **KWIC (Keyword in Context)**\n",
    "Termes d'intérêt : \n",
    "- « Programme »\n",
    "- « Plan »\n",
    "- « Service(s) de » \n",
    "- « Intervenant(e) en »\n",
    "- « Professionnel de »\n",
    "- « Institut (du/de) »\n",
    "- « Groupe de recherche en »\n",
    "- « Personne »\n",
    "- « Infirmière (en) »"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad7771b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans notre cas on veut que ça débute par le mot-clé donc le contexte est un peu plus simple\n",
    "# penser à généraliser avec des expressions régulières\n",
    "kw = ['programme', 'plan ', 'service', 'intervenant', 'infirmière en', 'institut', 'groupe de recherche', 'personne', 'maladie']\n",
    "\n",
    "ngrammes_kwic = [\" \".join([t[0].replace(\"' \", \"'\") for t in ng]) for ng in ngrammes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4c50b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "extrant = pd.DataFrame(columns=['Mot-clé','Concordance', 'Fréquence'])\n",
    "kwic = {w : [] for w in kw} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "255df07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ngrammes_kwic: # on pourrait aussi chercher dans les terms, mais on perd certains termes d'intérêt avec le filtrage syntaxique\n",
    "    for w in kw:\n",
    "        if t.startswith(w):\n",
    "            kwic[w].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e8fe7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic = {term: FreqDist(kwic[term]) for term in kwic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "645a8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in kw:\n",
    "    df = pd.DataFrame(kwic[term].items(), columns=['Concordance', \"Fréquence\"])\n",
    "    df.sort_values([\"Fréquence\"], \n",
    "        axis=0,\n",
    "        ascending=[False], \n",
    "        inplace=True)\n",
    "\n",
    "    df.insert(0, 'Mot-clé', term)\n",
    "    extrant = pd.concat([extrant, df])\n",
    "\n",
    "\n",
    "extrant = extrant[extrant['Fréquence'] > 30] \n",
    "\n",
    "file_path = '../04-filtrage/output/'\n",
    "if sous_corpus:\n",
    "    file_path = path.join(file_path, acteur, tag, tag)\n",
    "\n",
    "else :\n",
    "    file_path = path.join(file_path, acteur, acteur)\n",
    "\n",
    "\n",
    "extrant.to_csv(file_path + '_KWIC' +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45949eb3",
   "metadata": {},
   "source": [
    "### **Extraction de termes MeSH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c50c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "file_path = '../04-filtrage/mesh-fr.txt'\n",
    "\n",
    "with open (file_path, 'r', encoding='utf-8') as f:\n",
    "    mesh = [tuple(tokenizer_re.tokenize(w)) for w in f.readlines()]\n",
    "    tokenizer_mesh = MWETokenizer(mesh, separator= ' ')\n",
    "    mesh = [tokenizer_mesh.tokenize(w)[0].lower() for w in mesh]\n",
    "    mesh = [w for w in mesh if len(w.split()) > 1] # On ne retient que les termes complexes\n",
    "    #mesh = [tuple(t.strip('.').lower().split()) for t in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b2c0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "extr_mesh = tokenizer_mesh.tokenize([t[0] for t in terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f53c0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "termes_mesh = []\n",
    "\n",
    "for t in extr_mesh:\n",
    "    if t in mesh:\n",
    "        termes_mesh.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb21d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../04-filtrage/output/'\n",
    "if sous_corpus:\n",
    "    file_path = path.join(file_path, acteur, tag, tag)\n",
    "\n",
    "else :\n",
    "    file_path = path.join(file_path, acteur, acteur)\n",
    "\n",
    "df = DataFrame(termes_mesh)\n",
    "df.to_csv(file_path + '_MeSH.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685131ee",
   "metadata": {},
   "source": [
    "### **Extraction de termes SNOMED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb27c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "file_path = '../04-filtrage/SNOMED_fr.csv'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    sm = read_csv(f, sep=';')\n",
    "    sm = list(dict.fromkeys([str(t).strip().lower() for t in sm['term'].tolist()]))\n",
    "\n",
    "    sm = [tuple(tokenizer_re.tokenize(w)) for w in sm if len(w.split()) > 1]\n",
    "    tokenizer_sm = MWETokenizer(sm, separator = ' ')\n",
    "\n",
    "    sm = [tokenizer_sm.tokenize(w)[0].lower() for w in sm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3462f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "extr_sm = tokenizer_sm.tokenize([t[0] for t in terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41c006d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "termes_sm = []\n",
    "\n",
    "for t in extr_sm:\n",
    "    if t in sm:\n",
    "        termes_sm.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "645e5497",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../04-filtrage/output' \n",
    "if sous_corpus:\n",
    "    file_path = path.join(file_path, acteur, tag, tag) \n",
    "\n",
    "else :\n",
    "    file_path = path.join(file_path, acteur, acteur)\n",
    "\n",
    "\n",
    "df = DataFrame(termes_sm)\n",
    "\n",
    "df.to_csv(file_path + '_SNOMED.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "79bb76bbc4f9ba1f8df5efe8db67aae07079a51dc7b5004f49990e90f5993a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
