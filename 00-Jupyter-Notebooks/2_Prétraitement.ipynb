{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c662c7d",
   "metadata": {},
   "source": [
    "## **2. Prétraitement**\n",
    "- Segmentation (phrases)\n",
    "- Tokenization (mots)\n",
    "- Étiquetage morphosyntaxique (POS Tagging) \n",
    "- (Lemmatisation)\n",
    "- Filtrage (stopwords)\n",
    "- Extraction de termes complexes (MWE / n-grammes / segments répétés)\n",
    "- Chunking / Filtrage par patrons syntaxiques (basés sur les patrons fréquents dans les MeSH)\n",
    "- Extraction de collocations significatives (en fonction du Log-likelihood ratio)\n",
    "- Extraction de concordances (KWIC) pour un ensemble de mots-clés d'intérêt\n",
    "- Extraction de termes MeSH et SNOMED présents dans les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece38e9",
   "metadata": {},
   "source": [
    "### **Lire le corpus** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "0a62415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, re, pandas, random\n",
    "from os import listdir, chdir, path\n",
    "from pathlib import Path\n",
    "\n",
    "acteur = 'chum'\n",
    "sous_corpus = False \n",
    "tag = ''\n",
    "\n",
    "# Change the directory\n",
    "if sous_corpus:\n",
    "    base_path = '../03-corpus/2-sous-corpus/'\n",
    "    file_path = path.join(base_path, acteur, acteur + '_' + tag + '.csv')\n",
    "\n",
    "else: \n",
    "    base_path = '../03-corpus/2-data/1-fr/'\n",
    "    file_path = path.join(base_path, acteur) + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "a31c5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "with open(file_path, \"r\", encoding = \"UTF-8\") as f:\n",
    "        data = read_csv(file_path)['text'].tolist()\n",
    "        #data = data[~data[\"url\"].str.contains('pdf')] # Si on veut exclure les PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd537ec8",
   "metadata": {},
   "source": [
    "### **Nettoyage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "b8c10c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [t.strip('\\n').lower().replace('’', '\\'') for t in data]\n",
    "punct = '[!#$%&\\(\\)*+,-/:;<=>?@[\\]^_{|}~©«»—]'\n",
    "spaces = '\\s+'\n",
    "\n",
    "text = [re.sub(punct, ' ', t).replace(\"' \", \"'\" ) for t in text]\n",
    "text = [re.sub(spaces, ' ', t) for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "a4fda380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a un corpus de 2299 documents.\n"
     ]
    }
   ],
   "source": [
    "nb_docs = len(text)\n",
    "\n",
    "print(\"On a un corpus de {} documents.\".format(nb_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89c4d8",
   "metadata": {},
   "source": [
    "### **Extraire un échantillon aléatoire**\n",
    "\n",
    "Sinon, on n'arrive pas à traiter la totalité du corpus pour des raisons de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "69841ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On va travailler sur un échantillon correspondant à environ x % des documents du corpus, soit 2299 documents\n"
     ]
    }
   ],
   "source": [
    "n = round(1 * nb_docs)\n",
    "corpus = random.sample(text, n)\n",
    "\n",
    "print(\"On va travailler sur un échantillon correspondant à environ x % des documents du corpus, soit {} documents\". format(len(corpus)))\n",
    "\n",
    "corpus = \" \".join(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a4b16",
   "metadata": {},
   "source": [
    "**NLTK**\\\n",
    "https://www.nltk.org/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "31145e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download(['popular'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b5d73",
   "metadata": {},
   "source": [
    "### **Filtrage (MWE - stopwords formés de plusieurs tokens)**\n",
    "Surtout pour filtrer les expressions relatives à l'architecture d'information / navigation Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "2b7820d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../04-filtrage/mwe_stopwords.txt'\n",
    "\n",
    "with open (file_path, 'r', encoding='utf-8') as f:\n",
    "    mwe_sw = [t.lower().strip('\\n') for t in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "29a19b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mwe in mwe_sw:\n",
    "    corpus = corpus.replace(mwe, ' MWE_STOP ').replace('  ', \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8980c335",
   "metadata": {},
   "source": [
    "### **Tokenisation / POS tagging** (TreeTagger)  \n",
    "https://github.com/miotto/treetagger-python/blob/master/README.rst  \n",
    "https://treetaggerwrapper.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "eb94eec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avec le RegExpTokenizer, notre corpus contient 839760 tokens.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Seulement les caractères alphabétiques\n",
    "tokenizer_re = RegexpTokenizer(r\"\\w\\'|\\w+\")\n",
    "\n",
    "tokens = tokenizer_re.tokenize(corpus)\n",
    "\n",
    "print(\"Avec le RegExpTokenizer, notre corpus contient {} tokens.\".format(len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "237db34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le POS tagging devrait prendre environ 1 minutes.\n"
     ]
    }
   ],
   "source": [
    "temps = round(len(tokens) / 15000 / 60)\n",
    "print('Le POS tagging devrait prendre environ {} minutes.'.format(temps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "c07b565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \" \".join(tokens).replace(\"' \", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "047334bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import treetaggerwrapper\n",
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c195d",
   "metadata": {},
   "source": [
    "### **Mapping POS Tags** (FRMG)\n",
    "\n",
    "Pour utiliser adéquatement notre lemmatiseur par la suite (FrenchLefffLemmatizer), on va mapper les étiquettes morphosyntaxiques du TreeTagger à celles que prend le lemmatiseur (celles issues de FRMG)\n",
    "\n",
    "http://alpage.inria.fr/frmgwiki/content/tagset-frmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "7682234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '../04-filtrage/mapping_treeTagger_lefff.csv'\n",
    "\n",
    "#with open(file_path) as f:\n",
    "#    csv = read_csv(f)\n",
    "\n",
    "#treeTag = [term for term in csv['TreeTagger'].tolist()] \n",
    "#lefff = [term for term in csv['Lefff'].tolist()]\n",
    "\n",
    "#mapping = {term : lefff[treeTag.index(term)] for term in treeTag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "d991e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged = [[t.split('\\t')[0], mapping[t.split('\\t')[1]]] for t in tagger.tag_text(corpus)]\n",
    "#  mapping[t.split('\\t')[1]])\n",
    "tagged = [(t.split('\\t')[0], t.split('\\t')[1]) for t in tagger.tag_text(corpus)]\n",
    "\n",
    "\n",
    "#if len(t.split('\\t')) >1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "3f9363b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('christiane', 'NOM'),\n",
       " ('boulanger', 'ADJ'),\n",
       " ('MWE_STOP', 'NAM'),\n",
       " ('MWE_STOP', 'NAM'),\n",
       " ('MWE_STOP', 'NAM'),\n",
       " ('chum', 'NOM'),\n",
       " ('navigation', 'NOM'),\n",
       " ('MWE_STOP', 'NAM'),\n",
       " ('patients', 'ADJ'),\n",
       " ('répertoire', 'NOM'),\n",
       " ('enseignement', 'NOM'),\n",
       " ('et', 'KON'),\n",
       " ('académie', 'NOM'),\n",
       " ('centre', 'NOM'),\n",
       " ('de', 'PRP'),\n",
       " ('recherche', 'NOM'),\n",
       " ('innovation', 'NOM'),\n",
       " ('nouvelles', 'ADJ'),\n",
       " ('carrières', 'NOM'),\n",
       " ('MWE_STOP', 'NOM'),\n",
       " ('menu', 'ADJ'),\n",
       " ('sub', 'NOM'),\n",
       " ('haut', 'ADJ'),\n",
       " ('répertoire', 'NOM'),\n",
       " ('MWE_STOP', 'NAM')]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574866fe",
   "metadata": {},
   "source": [
    "### **Lemmatisation** (FrenchLefffLemmatizer)\n",
    "\n",
    "https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "a494e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "#lemmatizer = FrenchLefffLemmatizer()\n",
    "\n",
    "#lemmas = []\n",
    "#for term in tagged:\n",
    "#    term_l = []\n",
    "#    if lemmatizer.lemmatize(term[0], term[1]) == []:\n",
    "#        term_l = (lemmatizer.lemmatize(term[0]), term[1])\n",
    "    \n",
    "    # elif type(lemmatizer.lemmatize(term[0], term[1])) == str:\n",
    "    #     term_l  = (lemmatizer.lemmatize(term[0], term[1]), term[1])\n",
    "\n",
    "    # else:\n",
    "    #     term_l = tuple(lemmatizer.lemmatize(term[0], term[1])[0])\n",
    "    \n",
    "    # lemmas.append(term_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b5f4d",
   "metadata": {},
   "source": [
    "### **Collocations / Phrases / N-Grammes (MWE)**\n",
    "https://www.kaggle.com/code/alvations/n-gram-language-model-with-nltk/notebook  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "d4fc7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import everygrams\n",
    "ngrammes = list(everygrams(tagged, min_len=2, max_len=6))\n",
    "# ngrammes_lemmatized = list(everygrams(lemmas, min_len=2, max_len=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "18ecac95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant filtrage, on a 4198775 ngrammes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Avant filtrage, on a {} ngrammes.\".format(len(ngrammes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1d405",
   "metadata": {},
   "source": [
    "### **Extraction des patrons syntaxiques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "b0ecd6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patterns(ngrammes):\n",
    "    patterns = []\n",
    "\n",
    "    for ng in ngrammes:\n",
    "        phrase = [t[0] for t in ng]\n",
    "        pattern = [t[1] for t in ng]\n",
    "        patterns.append([phrase, pattern])\n",
    "        \n",
    "    return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "c83c3704",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = extract_patterns(ngrammes)\n",
    "# phrases_lemmatized = extract_patterns(ngrammes_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "b55a7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule la distribution de fréquences de nos n-grammes\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "freq = FreqDist([\" \".join(t[0]).replace(\"' \", \"'\") for t in phrases])\n",
    "# freq_lemmatized = FreqDist([\" \".join(t[0]).replace(\"' \", \"'\") for t in phrases_lemmatized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "261db806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MWE_STOP MWE_STOP', 10478),\n",
       " ('du chum', 8694),\n",
       " ('de la', 7539),\n",
       " ('de recherche', 6335),\n",
       " ('centre de', 5331),\n",
       " (\"à l'\", 5162),\n",
       " ('le chum', 5055),\n",
       " ('chum MWE_STOP', 4846),\n",
       " ('MWE_STOP MWE_STOP MWE_STOP', 4675),\n",
       " (\"de l'\", 4210),\n",
       " ('centre de recherche', 4044),\n",
       " ('de montréal', 3619),\n",
       " ('université de', 3437),\n",
       " ('université de montréal', 3297),\n",
       " (\"l'université\", 3063),\n",
       " (\"l'université de\", 2952),\n",
       " (\"l'université de montréal\", 2831),\n",
       " ('MWE_STOP patients', 2742),\n",
       " (\"à l'université\", 2521),\n",
       " (\"à l'université de\", 2480),\n",
       " (\"à l'université de montréal\", 2418),\n",
       " ('MWE_STOP le', 2410),\n",
       " ('chum est', 2410),\n",
       " ('du réseau', 2408),\n",
       " ('enseignement et', 2365)]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d93e86e",
   "metadata": {},
   "source": [
    "### **Filtrage** \n",
    "On retire les n-grammes qui débutent ou se terminent par un stopword (antidictionnaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "dd5d7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer l'antidictionnaire pour filtrer les données\n",
    "\n",
    "# # Stopwords lemmatisés\n",
    "# file_path = '../04-filtrage/stopwords_lemmatized.txt'\n",
    "# with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "#     stopwords_lemmatized = [w.strip('\\n').lower() for w in f.readlines()]\n",
    "\n",
    "# Stopwords fréquents en français (non lemmatisés)\n",
    "file_path = \"../04-filtrage/stopwords.txt\"\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    stopwords = [t.lower().strip('\\n') for t in f.readlines()]\n",
    "\n",
    "\n",
    "# Stopwords fréquents en anglais (non lemmatisés)\n",
    "file_path = '../04-filtrage/stop_words_english.txt'\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "    stopwords += [t.lower().strip('\\n') for t in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "52036bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrer_stopwords(x):\n",
    "    return [term for term in x if not 'MWE_STOP' in term[0] and not term[0][0] in stopwords and not term[0][-1] in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "86835f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = filtrer_stopwords(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a89e06",
   "metadata": {},
   "source": [
    "On retire les n-grammes qui débutent ou se terminent par un chiffre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "453fc4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_num(x):\n",
    "    return [term for term in x if not term[0][0].isnumeric() and not term[0][-1].isnumeric()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "0c4f428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = filter_num(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26da835",
   "metadata": {},
   "source": [
    "On retire les n-grammes qui débutent ou se terminent par token dont la longueur est inférieure à 2 caractères ou supérieure à 18 caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "28750634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_len(x):\n",
    "    return [term for term in x if \\\n",
    "        len(term[0][0]) > 2 and len(term[0][0]) < 18 and \\\n",
    "        len(term[0][-1]) > 2 and len(term[0][-1]) < 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "430f8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = filter_len(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "a26b47dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = [[\" \".join(term[0]).replace(\"' \", \"'\"), \" \".join(term[1])] for term in phrases]\n",
    "# phrases_lemmatized = filtrer_phrases(phrases_lemmatized, freq_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "7a5ced2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for phrase in phrases:\n",
    "    phrase.append(freq[phrase[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "c3edd530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après filtrage, on a 808011 occurrences de ngrammes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Après filtrage, on a {} occurrences de ngrammes.\".format(len(phrases))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "77d889bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expression</th>\n",
       "      <th>Patron syntaxique</th>\n",
       "      <th>Fréquence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patients répertoire</td>\n",
       "      <td>ADJ NOM</td>\n",
       "      <td>2298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patients répertoire enseignement</td>\n",
       "      <td>ADJ NOM NOM</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patients répertoire enseignement et académie</td>\n",
       "      <td>ADJ NOM NOM KON NOM</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patients répertoire enseignement et académie c...</td>\n",
       "      <td>ADJ NOM NOM KON NOM NOM</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>répertoire enseignement</td>\n",
       "      <td>NOM NOM</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808006</th>\n",
       "      <td>regroupement des retraités du chum</td>\n",
       "      <td>NOM PRP:det NOM PRP:det NOM</td>\n",
       "      <td>2297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808007</th>\n",
       "      <td>regroupement des retraités du chum ruisss</td>\n",
       "      <td>NOM PRP:det NOM PRP:det NOM ADJ</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808008</th>\n",
       "      <td>retraités du chum</td>\n",
       "      <td>NOM PRP:det NOM</td>\n",
       "      <td>2299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808009</th>\n",
       "      <td>retraités du chum ruisss</td>\n",
       "      <td>NOM PRP:det NOM ADJ</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808010</th>\n",
       "      <td>chum ruisss</td>\n",
       "      <td>NOM ADJ</td>\n",
       "      <td>2295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>808011 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Expression  \\\n",
       "0                                     patients répertoire   \n",
       "1                        patients répertoire enseignement   \n",
       "2            patients répertoire enseignement et académie   \n",
       "3       patients répertoire enseignement et académie c...   \n",
       "4                                 répertoire enseignement   \n",
       "...                                                   ...   \n",
       "808006                 regroupement des retraités du chum   \n",
       "808007          regroupement des retraités du chum ruisss   \n",
       "808008                                  retraités du chum   \n",
       "808009                           retraités du chum ruisss   \n",
       "808010                                        chum ruisss   \n",
       "\n",
       "                      Patron syntaxique  Fréquence  \n",
       "0                               ADJ NOM       2298  \n",
       "1                           ADJ NOM NOM       2295  \n",
       "2                   ADJ NOM NOM KON NOM       2295  \n",
       "3               ADJ NOM NOM KON NOM NOM       2295  \n",
       "4                               NOM NOM       2295  \n",
       "...                                 ...        ...  \n",
       "808006      NOM PRP:det NOM PRP:det NOM       2297  \n",
       "808007  NOM PRP:det NOM PRP:det NOM ADJ       2295  \n",
       "808008                  NOM PRP:det NOM       2299  \n",
       "808009              NOM PRP:det NOM ADJ       2295  \n",
       "808010                          NOM ADJ       2295  \n",
       "\n",
       "[808011 rows x 3 columns]"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(phrases, columns=[\"Expression\", \"Patron syntaxique\", \"Fréquence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "be52a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabCSV(phrases, titre):\n",
    "    base_path = '../04-filtrage/output/'\n",
    "    tab = DataFrame(phrases, columns=[\"Expression\", \"Patron syntaxique\", \"Fréquence\"]).drop_duplicates()\n",
    "    tab.sort_values([\"Fréquence\"], \n",
    "                        axis=0,\n",
    "                        ascending=[False], \n",
    "                        inplace=True)\n",
    "\n",
    "\n",
    "    file_path = path.join(base_path, acteur, acteur)\n",
    "    if sous_corpus:\n",
    "       file_path = path.join(base_path, acteur, tag, tag)\n",
    "    \n",
    "\n",
    "    Path(file_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    tab.to_csv(file_path + titre)\n",
    "\n",
    "    return tab.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "a3f79a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = tabCSV(phrases,'_n-grams.csv')\n",
    "# phrases_lemmatized = tabCSV(phrases_lemmatized, '_n-grams-lemmatized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "4acce1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après filtrage, on a 383246 ngrammes uniques.\n"
     ]
    }
   ],
   "source": [
    "print(\"Après filtrage, on a {} ngrammes uniques.\".format(len(phrases)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386aa5c",
   "metadata": {},
   "source": [
    "### **Filtrage (Patrons syntaxiques)**  \n",
    "Lossio-Ventura, J. A., Jonquet, C., Roche, M., & Teisseire, M. (2014). Biomedical Terminology Extraction : A new combination of Statistical and Web Mining Approaches. 421. https://hal-lirmm.ccsd.cnrs.fr/lirmm-01056598\n",
    "\n",
    "On veut aller extraire les structures syntaxiques les plus courantes dans les MeSH pour filtrer notre corpus selon celles-ci (inspiré de la méthodologie de l'article ci-dessus ; voir le Notebook *Mesh_extract.ipynb*). Pour ce faire, nous allons donc ne sélectionner que les ngrammes qui y correspondent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "15945967",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../04-filtrage/MeSH/mesh_patterns-fr.csv'\n",
    "\n",
    "with open (file_path, 'r') as f:\n",
    "    patterns = read_csv(f)\n",
    "    patterns = patterns['Structure'].tolist() #[:200] # # On peut aussi seulement prendree les 200 structures syntaxiques les plus fréquentes dans les MeSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "d1e03045",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [t for t in phrases if t[1] in patterns and not 'NOM NOM' in t[1]] # \n",
    "# terms_lemmatized = [t for t in phrases_lemmatized if t[1] in patterns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "4539e651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le filtrage syntaxique élimine environ 60 % des termes\n",
      "On avait 383246 ngrammes, on en a maintenant 153593.\n"
     ]
    }
   ],
   "source": [
    "print(\"Le filtrage syntaxique élimine environ {} % des termes\".format(round((len(phrases) - len(terms)) / len(phrases) * 100)))\n",
    "print(\"On avait {} ngrammes, \".format(len(phrases)) + \"on en a maintenant {}.\".format(len(terms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "b74b50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_terms(liste_terms, titre):\n",
    "    file_path = '../04-filtrage/output/'\n",
    "    tab = pd.DataFrame(terms, columns= [\"Expression\", \"Structure syntaxique\", \"Fréquence\"]).drop_duplicates(subset='Expression', keep=\"last\")\n",
    "    tab.sort_values([\"Fréquence\"], \n",
    "                        axis=0,\n",
    "                        ascending=[False], \n",
    "                        inplace=True)\n",
    "\n",
    "    if sous_corpus:\n",
    "        file_path = path.join(file_path, acteur, tag, tag)\n",
    "\n",
    "    else :\n",
    "        file_path = path.join(file_path, acteur, acteur)\n",
    "\n",
    "                    \n",
    "    tab.to_csv(file_path + titre)\n",
    "\n",
    "extract_terms(terms, '_terms.csv')\n",
    "#extract_terms(terms_lemmatized, '_terms-lemmatized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "e5df1087",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_patterns = DataFrame(terms, columns = [\"Expression\", \"Structure syntaxique\", \"Fréquence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "41c6a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_patterns = terms_patterns.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "6049e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_patterns = {}\n",
    "for term in terms_patterns:\n",
    "    exp = term['Expression']\n",
    "    pattern = term['Structure syntaxique']\n",
    "    dict_patterns[exp] = pattern\n",
    "\n",
    "# dict_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "e19bb40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expression</th>\n",
       "      <th>Structure syntaxique</th>\n",
       "      <th>Fréquence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>centre de recherche</td>\n",
       "      <td>VER:pres PRP NOM</td>\n",
       "      <td>4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>centre de recherche</td>\n",
       "      <td>NOM PRP NOM</td>\n",
       "      <td>4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fondation du chum</td>\n",
       "      <td>NOM PRP:det NOM</td>\n",
       "      <td>2352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enseignement et académie</td>\n",
       "      <td>NOM KON NOM</td>\n",
       "      <td>2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comité des usagers</td>\n",
       "      <td>NOM PRP:det NOM</td>\n",
       "      <td>2313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153588</th>\n",
       "      <td>immunologie en épidémiologie</td>\n",
       "      <td>NOM PRP NOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153589</th>\n",
       "      <td>virologie en immunologie en épidémiologie</td>\n",
       "      <td>NOM PRP NOM PRP NOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153590</th>\n",
       "      <td>domaines pertinents</td>\n",
       "      <td>NOM ADJ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153591</th>\n",
       "      <td>science dans plusieurs domaines</td>\n",
       "      <td>NOM PRP PRO:IND NOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153592</th>\n",
       "      <td>garde de la science</td>\n",
       "      <td>VER:pres PRP DET:ART NOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153593 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Expression      Structure syntaxique  \\\n",
       "0                             centre de recherche          VER:pres PRP NOM   \n",
       "1                             centre de recherche               NOM PRP NOM   \n",
       "2                               fondation du chum           NOM PRP:det NOM   \n",
       "3                        enseignement et académie               NOM KON NOM   \n",
       "4                              comité des usagers           NOM PRP:det NOM   \n",
       "...                                           ...                       ...   \n",
       "153588               immunologie en épidémiologie               NOM PRP NOM   \n",
       "153589  virologie en immunologie en épidémiologie       NOM PRP NOM PRP NOM   \n",
       "153590                        domaines pertinents                   NOM ADJ   \n",
       "153591            science dans plusieurs domaines       NOM PRP PRO:IND NOM   \n",
       "153592                        garde de la science  VER:pres PRP DET:ART NOM   \n",
       "\n",
       "        Fréquence  \n",
       "0            4044  \n",
       "1            4044  \n",
       "2            2352  \n",
       "3            2317  \n",
       "4            2313  \n",
       "...           ...  \n",
       "153588          1  \n",
       "153589          1  \n",
       "153590          1  \n",
       "153591          1  \n",
       "153592          1  \n",
       "\n",
       "[153593 rows x 3 columns]"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(terms_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1baa06e",
   "metadata": {},
   "source": [
    "### **Filtrage (Collocations statistiquement significatives)** Log-Likelihood Ratio\n",
    "\n",
    "[Notebook - Collocation extraction methodologies compared](https://notebooks.githubusercontent.com/view/ipynb?azure_maps_enabled=false&browser=chrome&color_mode=auto&commit=33868e847376764d7733cd958986c88dedfaec97&device=unknown&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f746f64642d636f6f6b2f4d4c2d596f752d43616e2d5573652f333338363865383437333736373634643737333363643935383938366338386465646661656339372f70726f626162696c69737469635f6c616e67756167655f6d6f64656c696e672f636f6c6c6f636174696f6e5f65787472616374696f6e732e6970796e62&enterprise_enabled=false&logged_in=false&nwo=todd-cook%2FML-You-Can-Use&path=probabilistic_language_modeling%2Fcollocation_extractions.ipynb&platform=android&repository_id=167140788&repository_type=Repository&version=102)\n",
    "\n",
    "On applique un test d'hypothèse statistique aux n-grammes sur lesquels une probabilité a été mesurée (Log-likelihood ratio) - seuls les n-grammes dont le test est significatif seront conservés.\n",
    "On considère que l'apparition de ces collocations dans notre corpus n'est pas dûe au hasard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "5cc17f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood_ratio(c_prior, c_n, c_ngram, N):\n",
    "    \"\"\"\n",
    "    Compute the ratio of two hypotheses of likelihood and return the ratio.\n",
    "    The formula here and test verification values are taken from \n",
    "    Manning & Schūtze _Foundations of Statistical Natural Language Processing_ p.172-175\n",
    "    Parameters:\n",
    "    c_prior: count of word 1 if bigrams or count of [w1w2 .. w(n-1)] if ngram\n",
    "    c_n : count of word 2 if bigrams or count of wn if ngram\n",
    "    c12: count of bigram (w1, w2) if bigram or count of ngram if ngram\n",
    "    N: the number of words in the corpus\n",
    "    \"\"\"\n",
    "\n",
    "    p = c_n / N\n",
    "    p1 = c_ngram / c_prior\n",
    "    p2 = (c_n - c_ngram) / (N - c_prior)   \n",
    "    # We proactively trap a runtimeWarning: divide by zero encountered in log,\n",
    "    # which may occur with extreme collocations\n",
    "    import warnings\n",
    "    with warnings.catch_warnings(): # this will reset our filterwarnings setting\n",
    "        warnings.filterwarnings('error')\n",
    "        try:\n",
    "            return (np.log(binom.pmf(c_ngram, c_prior, p)) \n",
    "                    + np.log(binom.pmf(c_n - c_ngram, N - c_prior, p)) \n",
    "                    - np.log(binom.pmf(c_ngram, c_prior, p1) )\n",
    "                    - np.log(binom.pmf(c_n - c_ngram, N - c_prior, p2)))             \n",
    "        except Warning:\n",
    "            return np.inf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "20e82354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Au départ, on a 153593 ngrammes.\n"
     ]
    }
   ],
   "source": [
    "len_prior = len(terms)\n",
    "print(\"Au départ, on a {} ngrammes.\".format(len_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "2891d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import binom, chi2\n",
    "from nltk import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "200f957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour le calcul des probabilités, on a besoin de traiter séparément les ngrammes selon la valeur de n\n",
    "N = len(tokens)\n",
    "fd_tokens = nltk.FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "f577b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llr_ngrammes(n):\n",
    "    llr = []\n",
    "\n",
    "    for i in range(2, n+1):\n",
    "        ngrammes = set([tuple(tokenizer_re.tokenize(term[0])) for term in terms if len(tokenizer_re.tokenize(term[0])) == i])\n",
    "        fd = nltk.FreqDist(ngrams(tokens, n=i))\n",
    "        fd_prior = nltk.FreqDist(ngrams(tokens, n=i-1))\n",
    "        \n",
    "        for t in ngrammes:\n",
    "            c_prior = fd_prior[t[:i-1]] # Antécédent = P(w1w2..w_n-1) (si on considère que P(w1w2...wn) = P(wn) | P(w1w2...w_n-1)\n",
    "            c_n = fd_tokens[t[i-1]]     # Dernier mot du ngramme  P(wn)\n",
    "            c_ngram = fd[t]             # Le ngramme lui-même P(w1w2w3..wn)\n",
    "\n",
    "            res = -2 * loglikelihood_ratio(c_prior, c_n, c_ngram, N)\n",
    "            p = chi2.sf(res, 1) # 1 degrees of freedom\n",
    "            #if res == float('-inf') :\n",
    "            #    res = 50000\n",
    "\n",
    "            if p < 0.05 or (res == float('-inf')):\n",
    "                llr.append({'Collocation' : \" \".join(t).replace(\"' \", \"'\"), 'Structure syntaxique': dict_patterns[\" \".join(t).replace(\"' \", \"'\")], 'Fréquence' : c_ngram, 'LLR': res, 'p-value': p})\n",
    "\n",
    "    return llr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "810a7a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = llr_ngrammes(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cddc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Après avoir calculé le log-likelihood ratio, on a retiré 12 collocations qui n'étaient pas statistiquement significatives.\n",
      "Ça représente environ 1 % de nos n-grammes.\n"
     ]
    }
   ],
   "source": [
    "print('Après avoir calculé le log-likelihood ratio, on a retiré {} collocations qui n\\'étaient pas statistiquement significatives.'.format(len_prior - len(terms)))\n",
    "print('Ça représente environ {} % de nos n-grammes.'.format(round((len_prior - len(terms)) / len_prior *100 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffcb628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collocation</th>\n",
       "      <th>Structure syntaxique</th>\n",
       "      <th>Fréquence</th>\n",
       "      <th>LLR</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>centre de recherche</td>\n",
       "      <td>NOM PRP NOM</td>\n",
       "      <td>34</td>\n",
       "      <td>258.960385</td>\n",
       "      <td>2.891539e-58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>fondation du chum</td>\n",
       "      <td>NOM PRP:det NOM</td>\n",
       "      <td>23</td>\n",
       "      <td>164.166818</td>\n",
       "      <td>1.390975e-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>enseignement et académie</td>\n",
       "      <td>NOM KON NOM</td>\n",
       "      <td>23</td>\n",
       "      <td>297.851259</td>\n",
       "      <td>9.680887e-67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>regroupement des retraités du chum</td>\n",
       "      <td>NOM PRP:det NOM PRP:det NOM</td>\n",
       "      <td>22</td>\n",
       "      <td>156.911497</td>\n",
       "      <td>5.351667e-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>commissaire local aux plaintes politique</td>\n",
       "      <td>NOM ADJ PRP:det NOM ADJ</td>\n",
       "      <td>22</td>\n",
       "      <td>294.812807</td>\n",
       "      <td>4.445477e-66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>inscription l'objectif</td>\n",
       "      <td>NOM DET:ART NOM</td>\n",
       "      <td>1</td>\n",
       "      <td>19.585858</td>\n",
       "      <td>9.617847e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>bout du drain</td>\n",
       "      <td>NOM PRP:det NOM</td>\n",
       "      <td>1</td>\n",
       "      <td>14.581834</td>\n",
       "      <td>1.342020e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>démontrer l'impact</td>\n",
       "      <td>VER:infi DET:ART NOM</td>\n",
       "      <td>1</td>\n",
       "      <td>16.813270</td>\n",
       "      <td>4.124389e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>hassan falcone émilia</td>\n",
       "      <td>ADJ NOM VER:simp</td>\n",
       "      <td>1</td>\n",
       "      <td>19.585858</td>\n",
       "      <td>9.617847e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>déclaration de montréal pour un développement</td>\n",
       "      <td>NOM PRP NOM PRP DET:ART NOM</td>\n",
       "      <td>1</td>\n",
       "      <td>15.087177</td>\n",
       "      <td>1.026583e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1551 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Collocation  \\\n",
       "541                             centre de recherche   \n",
       "446                               fondation du chum   \n",
       "420                        enseignement et académie   \n",
       "1289             regroupement des retraités du chum   \n",
       "1237       commissaire local aux plaintes politique   \n",
       "...                                             ...   \n",
       "550                          inscription l'objectif   \n",
       "549                                   bout du drain   \n",
       "548                              démontrer l'impact   \n",
       "547                           hassan falcone émilia   \n",
       "1550  déclaration de montréal pour un développement   \n",
       "\n",
       "             Structure syntaxique  Fréquence         LLR       p-value  \n",
       "541                   NOM PRP NOM         34  258.960385  2.891539e-58  \n",
       "446               NOM PRP:det NOM         23  164.166818  1.390975e-37  \n",
       "420                   NOM KON NOM         23  297.851259  9.680887e-67  \n",
       "1289  NOM PRP:det NOM PRP:det NOM         22  156.911497  5.351667e-36  \n",
       "1237      NOM ADJ PRP:det NOM ADJ         22  294.812807  4.445477e-66  \n",
       "...                           ...        ...         ...           ...  \n",
       "550               NOM DET:ART NOM          1   19.585858  9.617847e-06  \n",
       "549               NOM PRP:det NOM          1   14.581834  1.342020e-04  \n",
       "548          VER:infi DET:ART NOM          1   16.813270  4.124389e-05  \n",
       "547              ADJ NOM VER:simp          1   19.585858  9.617847e-06  \n",
       "1550  NOM PRP NOM PRP DET:ART NOM          1   15.087177  1.026583e-04  \n",
       "\n",
       "[1551 rows x 5 columns]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(terms).sort_values(by = \"Fréquence\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f235b77",
   "metadata": {},
   "source": [
    "### **Filtrage - Fréquence documentaire**\n",
    "** Il y aurait quelque chose à modifier ici ; en tokenisant, on supprimer les frontières entre les mots qui sont des tirets ou autres caractères qu'un espace ou un apostrophe ; ça fait en sorte qu'on a une fréquence documentaire de 0 pour les ngrammes qui n'ont plus la forme exacte qu'ils avaient dans le corpus orginal. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {term['Collocation']: len([doc for doc in text if term['Collocation'] in doc]) for term in terms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9194dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {term for term in dfs if dfs[term] == 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284919f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action 2018 medteq',\n",
       " 'chum groupe voyages',\n",
       " 'commission cv disease',\n",
       " 'commission cv disease across the lifespan',\n",
       " 'innove action 2018 medteq',\n",
       " 'lancet commission cv disease',\n",
       " 'speaker lancet commission cv disease'}"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df = round(0.98 * nb_docs)        # Pour rejeter les termes qui se retrouvent dans 98% des documents \n",
    "terms = [t for t in terms if dfs[t['Collocation']] < max_df and dfs[t['Collocation']] > 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359835a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collocation</th>\n",
       "      <th>Structure syntaxique</th>\n",
       "      <th>Fréquence</th>\n",
       "      <th>LLR</th>\n",
       "      <th>p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>centre de prélèvement</td>\n",
       "      <td>VER:pres PRP NOM</td>\n",
       "      <td>15</td>\n",
       "      <td>151.428038</td>\n",
       "      <td>8.449563e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>retrouver dans l'hôpital</td>\n",
       "      <td>VER:infi PRP DET:ART NOM</td>\n",
       "      <td>13</td>\n",
       "      <td>176.123545</td>\n",
       "      <td>3.402966e-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>chum pour vous retrouver</td>\n",
       "      <td>NOM PRP PRO:PER VER:infi</td>\n",
       "      <td>13</td>\n",
       "      <td>187.903779</td>\n",
       "      <td>9.118087e-43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>plan du chum</td>\n",
       "      <td>NOM PRP:det NOM</td>\n",
       "      <td>13</td>\n",
       "      <td>92.106552</td>\n",
       "      <td>8.213297e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>urgence le chum</td>\n",
       "      <td>NOM DET:ART NOM</td>\n",
       "      <td>13</td>\n",
       "      <td>71.120179</td>\n",
       "      <td>3.361147e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>voyages au profit</td>\n",
       "      <td>NOM PRP:det NOM</td>\n",
       "      <td>1</td>\n",
       "      <td>19.585858</td>\n",
       "      <td>9.617847e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>transplantation une occasion</td>\n",
       "      <td>NOM DET:ART NOM</td>\n",
       "      <td>1</td>\n",
       "      <td>16.813270</td>\n",
       "      <td>4.124389e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>travaux ont permis</td>\n",
       "      <td>NOM VER:pres VER:pper</td>\n",
       "      <td>1</td>\n",
       "      <td>19.585858</td>\n",
       "      <td>9.617847e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>expérimentation par excellence</td>\n",
       "      <td>NOM PRP NOM</td>\n",
       "      <td>1</td>\n",
       "      <td>15.087177</td>\n",
       "      <td>1.026583e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>déclaration de montréal pour un développement</td>\n",
       "      <td>NOM PRP NOM PRP DET:ART NOM</td>\n",
       "      <td>1</td>\n",
       "      <td>15.087177</td>\n",
       "      <td>1.026583e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1515 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Collocation  \\\n",
       "808                           centre de prélèvement   \n",
       "1140                       retrouver dans l'hôpital   \n",
       "1126                       chum pour vous retrouver   \n",
       "815                                    plan du chum   \n",
       "693                                 urgence le chum   \n",
       "...                                             ...   \n",
       "532                               voyages au profit   \n",
       "531                    transplantation une occasion   \n",
       "530                              travaux ont permis   \n",
       "529                  expérimentation par excellence   \n",
       "1514  déclaration de montréal pour un développement   \n",
       "\n",
       "             Structure syntaxique  Fréquence         LLR       p-value  \n",
       "808              VER:pres PRP NOM         15  151.428038  8.449563e-35  \n",
       "1140     VER:infi PRP DET:ART NOM         13  176.123545  3.402966e-40  \n",
       "1126     NOM PRP PRO:PER VER:infi         13  187.903779  9.118087e-43  \n",
       "815               NOM PRP:det NOM         13   92.106552  8.213297e-22  \n",
       "693               NOM DET:ART NOM         13   71.120179  3.361147e-17  \n",
       "...                           ...        ...         ...           ...  \n",
       "532               NOM PRP:det NOM          1   19.585858  9.617847e-06  \n",
       "531               NOM DET:ART NOM          1   16.813270  4.124389e-05  \n",
       "530         NOM VER:pres VER:pper          1   19.585858  9.617847e-06  \n",
       "529                   NOM PRP NOM          1   15.087177  1.026583e-04  \n",
       "1514  NOM PRP NOM PRP DET:ART NOM          1   15.087177  1.026583e-04  \n",
       "\n",
       "[1515 rows x 5 columns]"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for term in terms:\n",
    "#    term['DF'] = dfs[term['Collocation']] \n",
    "DataFrame(terms).sort_values(by=\"Fréquence\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c08c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(terms)\n",
    "df.sort_values(['Fréquence'], \n",
    "            axis=0,\n",
    "            ascending=[False], \n",
    "            inplace=True)\n",
    "\n",
    "output_path = path.join('../04-filtrage/output/', acteur, acteur + '_significant-collocations.csv') \n",
    "df.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847ef6e6",
   "metadata": {},
   "source": [
    "### **KWIC (Keyword in Context)**\n",
    "Termes d'intérêt : \n",
    "- « Programme »\n",
    "- « Plan »\n",
    "- « Service(s) de » \n",
    "- « Intervenant(e) en »\n",
    "- « Professionnel de »\n",
    "- « Institut (du/de) »\n",
    "- « Groupe de recherche en »\n",
    "- « Personne »\n",
    "- « Infirmière (en) »"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7771b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans notre cas on veut que ça débute par le mot-clé donc le contexte est un peu plus simple\n",
    "# penser à généraliser avec des expressions régulières\n",
    "kw = ['programme', 'plan ', 'service', 'intervenant', 'infirmière en', 'institut', 'groupe de recherche', 'personne', 'maladie']\n",
    "\n",
    "ngrammes_kwic = [\" \".join([t[0] for t in ng]).replace(\"' \", \"'\") for ng in ngrammes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c50b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "extrant = pd.DataFrame(columns=['Mot-clé','Concordance', 'Fréquence'])\n",
    "kwic = {w : [] for w in kw} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255df07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ngrammes_kwic: # on pourrait aussi chercher dans les terms, mais on perd certains termes d'intérêt avec le filtrage syntaxique\n",
    "    for w in kw:\n",
    "        if t.startswith(w):\n",
    "            kwic[w].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8fe7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwic = {term: FreqDist(kwic[term]) for term in kwic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645a8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in kw:\n",
    "    df = pd.DataFrame(kwic[term].items(), columns=['Concordance', \"Fréquence\"])\n",
    "    df.sort_values([\"Fréquence\"], \n",
    "        axis=0,\n",
    "        ascending=[False], \n",
    "        inplace=True)\n",
    "\n",
    "    df.insert(0, 'Mot-clé', term)\n",
    "    extrant = pd.concat([extrant, df])\n",
    "\n",
    "\n",
    "extrant = extrant[extrant['Fréquence'] > 30] \n",
    "\n",
    "file_path = '../04-filtrage/output/'\n",
    "if sous_corpus:\n",
    "    file_path = path.join(file_path, acteur, tag, tag)\n",
    "\n",
    "else :\n",
    "    file_path = path.join(file_path, acteur, acteur)\n",
    "\n",
    "\n",
    "extrant.to_csv(file_path + '_KWIC' +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45949eb3",
   "metadata": {},
   "source": [
    "### **Extraction de termes MeSH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "file_path = '../04-filtrage/MeSH/mesh-fr.txt'\n",
    "\n",
    "with open (file_path, 'r', encoding='utf-8') as f:\n",
    "    mesh = [tuple(tokenizer_re.tokenize(w)) for w in f.readlines()]\n",
    "    tokenizer_mesh = MWETokenizer(mesh, separator= ' ')\n",
    "    mesh = [tokenizer_mesh.tokenize(w)[0].lower() for w in mesh]\n",
    "    mesh = [w for w in mesh if len(w.split()) > 1] # On ne retient que les termes complexes\n",
    "    #mesh = [tuple(t.strip('.').lower().split()) for t in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "extr_mesh = tokenizer_mesh.tokenize([t['Collocation'] for t in terms])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40edc2e1",
   "metadata": {},
   "source": [
    "# **MODIF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFICATION À APPORTER : dans l'extrant où on voit les termes mesh, ajouter la fréquence\n",
    "\n",
    "termes_mesh[:15]\n",
    "\n",
    "for t in termes_mesh:\n",
    "    print(t, corpus.count(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "termes_mesh = []\n",
    "\n",
    "for t in extr_mesh:\n",
    "    if t in mesh:\n",
    "        termes_mesh.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb21d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../04-filtrage/output/'\n",
    "if sous_corpus:\n",
    "    file_path = path.join(file_path, acteur, tag, tag)\n",
    "\n",
    "else :\n",
    "    file_path = path.join(file_path, acteur, acteur)\n",
    "\n",
    "df = DataFrame(termes_mesh)\n",
    "df.to_csv(file_path + '_MeSH.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685131ee",
   "metadata": {},
   "source": [
    "### **Extraction de termes SNOMED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb27c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "file_path = '../04-filtrage/SNOMED_fr.csv'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    sm = read_csv(f, sep=';')\n",
    "    sm = list(dict.fromkeys([str(t).strip().lower() for t in sm['term'].tolist()]))\n",
    "\n",
    "    sm = [tuple(tokenizer_re.tokenize(w)) for w in sm if len(w.split()) > 1]\n",
    "    tokenizer_sm = MWETokenizer(sm, separator = ' ')\n",
    "\n",
    "    sm = [tokenizer_sm.tokenize(w)[0].lower() for w in sm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3462f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "extr_sm = tokenizer_sm.tokenize([t[0] for t in terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c006d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "termes_sm = []\n",
    "\n",
    "for t in extr_sm:\n",
    "    if t in sm:\n",
    "        termes_sm.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e5497",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../04-filtrage/output' \n",
    "if sous_corpus:\n",
    "    file_path = path.join(file_path, acteur, tag, tag) \n",
    "\n",
    "else :\n",
    "    file_path = path.join(file_path, acteur, acteur)\n",
    "\n",
    "\n",
    "df = DataFrame(termes_sm)\n",
    "\n",
    "df.to_csv(file_path + '_SNOMED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10875e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "79bb76bbc4f9ba1f8df5efe8db67aae07079a51dc7b5004f49990e90f5993a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
